{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m-%d-%H_%M_%S')\n",
    "    return os.path.join(os.path.join(os.curdir,'my_logs'), run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A & B) Regular DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (45000, 32, 32, 3)\n",
      "Label shape: (45000, 1)\n",
      "Number of labels: 10\n"
     ]
    }
   ],
   "source": [
    "(X_tfull,y_tfull) , (X_test,y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_tfull[5000:]\n",
    "y_train = y_tfull[5000:]\n",
    "X_val = X_tfull[:5000]\n",
    "y_val = y_tfull[:5000]\n",
    "\n",
    "print('Feature shape: ' + str(X_train.shape))\n",
    "print('Label shape: ' + str(y_train.shape))\n",
    "print('Number of labels: ' + str(len(np.unique(y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Model and Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (32,32,3),name = 'flat_in'))\n",
    "\n",
    "for i in range(20): #add 20 layers\n",
    "    model.add(keras.layers.Dense(100,activation = 'elu',name = f'dense_{i}',kernel_initializer = 'HeNormal'))\n",
    "\n",
    "model.add(keras.layers.Dense(10,activation = 'softmax',name = 'dense_out'))\n",
    "\n",
    "my_opt = keras.optimizers.Nadam(learning_rate = 5e-5)\n",
    "model.compile(optimizer = my_opt, loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define learning rate schedule and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_lr_schedule(epoch,lr):\n",
    "    all_lrs = 10**np.linspace(-7,1.1,100,dtype = float)\n",
    "    return all_lrs[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 26s 14ms/step - loss: 116.8075 - accuracy: 0.0931 - val_loss: 74.7765 - val_accuracy: 0.0908 - lr: 1.0000e-07\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 62.5933 - accuracy: 0.0960 - val_loss: 50.2995 - val_accuracy: 0.1044 - lr: 1.2073e-07\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 44.0928 - accuracy: 0.1021 - val_loss: 36.9694 - val_accuracy: 0.1130 - lr: 1.4576e-07\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 32.9147 - accuracy: 0.1024 - val_loss: 27.9838 - val_accuracy: 0.1104 - lr: 1.7598e-07\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 25.2135 - accuracy: 0.1077 - val_loss: 21.5021 - val_accuracy: 0.1130 - lr: 2.1246e-07\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 19.1507 - accuracy: 0.1092 - val_loss: 16.2803 - val_accuracy: 0.1114 - lr: 2.5650e-07\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 14.2344 - accuracy: 0.1087 - val_loss: 12.0882 - val_accuracy: 0.1094 - lr: 3.0968e-07\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 10.7976 - accuracy: 0.1046 - val_loss: 9.4716 - val_accuracy: 0.1086 - lr: 3.7388e-07\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 8.5473 - accuracy: 0.1055 - val_loss: 7.6167 - val_accuracy: 0.1072 - lr: 4.5138e-07\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 6.8785 - accuracy: 0.1096 - val_loss: 6.2302 - val_accuracy: 0.1120 - lr: 5.4496e-07\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 5.6494 - accuracy: 0.1158 - val_loss: 5.1824 - val_accuracy: 0.1178 - lr: 6.5793e-07\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 4.7623 - accuracy: 0.1234 - val_loss: 4.3767 - val_accuracy: 0.1254 - lr: 7.9433e-07\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 4.0807 - accuracy: 0.1282 - val_loss: 3.7804 - val_accuracy: 0.1208 - lr: 9.5900e-07\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 3.5284 - accuracy: 0.1294 - val_loss: 3.3128 - val_accuracy: 0.1272 - lr: 1.1578e-06\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 3.1018 - accuracy: 0.1367 - val_loss: 2.9774 - val_accuracy: 0.1398 - lr: 1.3978e-06\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 2.7776 - accuracy: 0.1472 - val_loss: 2.6982 - val_accuracy: 0.1436 - lr: 1.6876e-06\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.5455 - accuracy: 0.1585 - val_loss: 2.4979 - val_accuracy: 0.1616 - lr: 2.0375e-06\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.3890 - accuracy: 0.1722 - val_loss: 2.3470 - val_accuracy: 0.1854 - lr: 2.4599e-06\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.2782 - accuracy: 0.1891 - val_loss: 2.2480 - val_accuracy: 0.1918 - lr: 2.9698e-06\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.1959 - accuracy: 0.2046 - val_loss: 2.1807 - val_accuracy: 0.2046 - lr: 3.5855e-06\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.1325 - accuracy: 0.2217 - val_loss: 2.1150 - val_accuracy: 0.2248 - lr: 4.3288e-06\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.0798 - accuracy: 0.2375 - val_loss: 2.0652 - val_accuracy: 0.2506 - lr: 5.2261e-06\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.0256 - accuracy: 0.2560 - val_loss: 2.0047 - val_accuracy: 0.2628 - lr: 6.3096e-06\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.9793 - accuracy: 0.2711 - val_loss: 1.9549 - val_accuracy: 0.2852 - lr: 7.6176e-06\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.9380 - accuracy: 0.2868 - val_loss: 1.9281 - val_accuracy: 0.2922 - lr: 9.1968e-06\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.9007 - accuracy: 0.3004 - val_loss: 1.9006 - val_accuracy: 0.3002 - lr: 1.1103e-05\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8681 - accuracy: 0.3141 - val_loss: 1.8700 - val_accuracy: 0.3248 - lr: 1.3405e-05\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8403 - accuracy: 0.3267 - val_loss: 1.8339 - val_accuracy: 0.3320 - lr: 1.6184e-05\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8107 - accuracy: 0.3383 - val_loss: 1.7922 - val_accuracy: 0.3438 - lr: 1.9539e-05\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7869 - accuracy: 0.3480 - val_loss: 1.8009 - val_accuracy: 0.3436 - lr: 2.3590e-05\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7614 - accuracy: 0.3612 - val_loss: 1.7620 - val_accuracy: 0.3626 - lr: 2.8480e-05\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7355 - accuracy: 0.3722 - val_loss: 1.7293 - val_accuracy: 0.3776 - lr: 3.4385e-05\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7179 - accuracy: 0.3814 - val_loss: 1.7294 - val_accuracy: 0.3774 - lr: 4.1513e-05\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6949 - accuracy: 0.3847 - val_loss: 1.7121 - val_accuracy: 0.3856 - lr: 5.0119e-05\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6795 - accuracy: 0.3916 - val_loss: 1.7217 - val_accuracy: 0.3832 - lr: 6.0509e-05\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6655 - accuracy: 0.4003 - val_loss: 1.6544 - val_accuracy: 0.3982 - lr: 7.3053e-05\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6570 - accuracy: 0.4031 - val_loss: 1.6688 - val_accuracy: 0.3990 - lr: 8.8197e-05\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6419 - accuracy: 0.4083 - val_loss: 1.6895 - val_accuracy: 0.3902 - lr: 1.0648e-04\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6323 - accuracy: 0.4134 - val_loss: 1.6557 - val_accuracy: 0.4120 - lr: 1.2856e-04\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6267 - accuracy: 0.4172 - val_loss: 1.6962 - val_accuracy: 0.3920 - lr: 1.5521e-04\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6159 - accuracy: 0.4196 - val_loss: 1.6377 - val_accuracy: 0.4088 - lr: 1.8738e-04\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6191 - accuracy: 0.4205 - val_loss: 1.7819 - val_accuracy: 0.3822 - lr: 2.2623e-04\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.6168 - accuracy: 0.4218 - val_loss: 1.5969 - val_accuracy: 0.4274 - lr: 2.7313e-04\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6161 - accuracy: 0.4245 - val_loss: 1.7822 - val_accuracy: 0.3488 - lr: 3.2975e-04\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6217 - accuracy: 0.4218 - val_loss: 1.6360 - val_accuracy: 0.4100 - lr: 3.9811e-04\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6299 - accuracy: 0.4187 - val_loss: 1.6427 - val_accuracy: 0.4288 - lr: 4.8064e-04\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6336 - accuracy: 0.4167 - val_loss: 1.6612 - val_accuracy: 0.4014 - lr: 5.8028e-04\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.6438 - accuracy: 0.4127 - val_loss: 1.6899 - val_accuracy: 0.3932 - lr: 7.0057e-04\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6516 - accuracy: 0.4108 - val_loss: 1.8562 - val_accuracy: 0.3506 - lr: 8.4581e-04\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6688 - accuracy: 0.4034 - val_loss: 1.7885 - val_accuracy: 0.3662 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6905 - accuracy: 0.3948 - val_loss: 1.6896 - val_accuracy: 0.3990 - lr: 0.0012\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.0627 - accuracy: 0.1888 - val_loss: 1.9936 - val_accuracy: 0.1972 - lr: 0.0015\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 30.6930 - accuracy: 0.1624 - val_loss: 2.0640 - val_accuracy: 0.1952 - lr: 0.0018\n"
     ]
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(my_lr_schedule)\n",
    "save_cb = keras.callbacks.ModelCheckpoint('my_cifar10_lr_search.h5',save_best_only=True)\n",
    "tb_cb = keras.callbacks.TensorBoard(get_run_logdir(),)\n",
    "\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs = 100, validation_data = (X_val,y_val),callbacks = [early_cb,save_cb,tb_cb,lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'min loss: 0.00027312638121657073')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(ncols = 2, figsize = (10,3))\n",
    "\n",
    "df.plot(x = 'lr',y = 'val_loss',color = 'b',marker= 'o',ax = ax[0])\n",
    "\n",
    "min_loss = np.argmin(df['val_loss'])\n",
    "min_lr = df.loc[min_loss,'lr']\n",
    "\n",
    "df.plot(x = 'lr',y = 'val_loss',color = 'b', marker = 'o',ax = ax[1]); plt.xlim([min_lr*.1 , min_lr*1.5]); plt.title(f'min loss: {min_lr}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on optimum learning level (10X than the minimum above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (32,32,3),name = 'flat_in'))\n",
    "\n",
    "for i in range(20): #add 20 layers\n",
    "    model.add(keras.layers.Dense(100,activation = 'elu',name = f'dense_{i}',kernel_initializer = 'HeNormal'))\n",
    "\n",
    "model.add(keras.layers.Dense(10,activation = 'softmax',name = 'dense_out'))\n",
    "\n",
    "my_opt = keras.optimizers.Nadam(learning_rate = 2.7e-5)\n",
    "model.compile(optimizer = my_opt, loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 22s 12ms/step - loss: 5.0479 - accuracy: 0.1501 - val_loss: 2.3078 - val_accuracy: 0.1884\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.1542 - accuracy: 0.2184 - val_loss: 2.3808 - val_accuracy: 0.1954\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 2.0171 - accuracy: 0.2611 - val_loss: 2.1486 - val_accuracy: 0.2292\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.9243 - accuracy: 0.2953 - val_loss: 1.8959 - val_accuracy: 0.3148\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8575 - accuracy: 0.3246 - val_loss: 1.8502 - val_accuracy: 0.3190\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8040 - accuracy: 0.3462 - val_loss: 1.8170 - val_accuracy: 0.3342\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7596 - accuracy: 0.3624 - val_loss: 1.7911 - val_accuracy: 0.3424\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7210 - accuracy: 0.3778 - val_loss: 1.7055 - val_accuracy: 0.3836\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6894 - accuracy: 0.3890 - val_loss: 1.6983 - val_accuracy: 0.3894\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 18s 12ms/step - loss: 1.6630 - accuracy: 0.3988 - val_loss: 1.6960 - val_accuracy: 0.3844\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6372 - accuracy: 0.4094 - val_loss: 1.7053 - val_accuracy: 0.3812\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.6164 - accuracy: 0.4174 - val_loss: 1.6564 - val_accuracy: 0.3898\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5958 - accuracy: 0.4256 - val_loss: 1.6639 - val_accuracy: 0.3988\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5780 - accuracy: 0.4303 - val_loss: 1.6153 - val_accuracy: 0.4096\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5612 - accuracy: 0.4353 - val_loss: 1.5947 - val_accuracy: 0.4260\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5416 - accuracy: 0.4425 - val_loss: 1.5927 - val_accuracy: 0.4270\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.5259 - accuracy: 0.4498 - val_loss: 1.5928 - val_accuracy: 0.4340\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5127 - accuracy: 0.4510 - val_loss: 1.6246 - val_accuracy: 0.4210\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5005 - accuracy: 0.4594 - val_loss: 1.5825 - val_accuracy: 0.4354\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4881 - accuracy: 0.4624 - val_loss: 1.5780 - val_accuracy: 0.4348\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4747 - accuracy: 0.4673 - val_loss: 1.5700 - val_accuracy: 0.4418\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4616 - accuracy: 0.4737 - val_loss: 1.5478 - val_accuracy: 0.4506\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.4488 - accuracy: 0.4758 - val_loss: 1.5797 - val_accuracy: 0.4364\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4382 - accuracy: 0.4819 - val_loss: 1.5519 - val_accuracy: 0.4436\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4254 - accuracy: 0.4869 - val_loss: 1.5439 - val_accuracy: 0.4524\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4153 - accuracy: 0.4892 - val_loss: 1.5610 - val_accuracy: 0.4490\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.4008 - accuracy: 0.4958 - val_loss: 1.5461 - val_accuracy: 0.4470\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3945 - accuracy: 0.4955 - val_loss: 1.5749 - val_accuracy: 0.4352\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3849 - accuracy: 0.5015 - val_loss: 1.5499 - val_accuracy: 0.4550\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3749 - accuracy: 0.5046 - val_loss: 1.5412 - val_accuracy: 0.4574\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3654 - accuracy: 0.5073 - val_loss: 1.5482 - val_accuracy: 0.4534\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3571 - accuracy: 0.5136 - val_loss: 1.5268 - val_accuracy: 0.4598\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3478 - accuracy: 0.5157 - val_loss: 1.5261 - val_accuracy: 0.4644\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3390 - accuracy: 0.5165 - val_loss: 1.6062 - val_accuracy: 0.4420\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3280 - accuracy: 0.5231 - val_loss: 1.5441 - val_accuracy: 0.4572\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3220 - accuracy: 0.5240 - val_loss: 1.5217 - val_accuracy: 0.4646\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3113 - accuracy: 0.5291 - val_loss: 1.5451 - val_accuracy: 0.4574\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3050 - accuracy: 0.5308 - val_loss: 1.5435 - val_accuracy: 0.4604\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2953 - accuracy: 0.5340 - val_loss: 1.5564 - val_accuracy: 0.4600\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2872 - accuracy: 0.5379 - val_loss: 1.5754 - val_accuracy: 0.4576\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2820 - accuracy: 0.5385 - val_loss: 1.5587 - val_accuracy: 0.4578\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2745 - accuracy: 0.5414 - val_loss: 1.5479 - val_accuracy: 0.4678\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2653 - accuracy: 0.5435 - val_loss: 1.5451 - val_accuracy: 0.4648\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2576 - accuracy: 0.5493 - val_loss: 1.5644 - val_accuracy: 0.4528\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2504 - accuracy: 0.5524 - val_loss: 1.5461 - val_accuracy: 0.4684\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2427 - accuracy: 0.5510 - val_loss: 1.5510 - val_accuracy: 0.4632\n"
     ]
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)\n",
    "save_cb = keras.callbacks.ModelCheckpoint('my_cifar10_default.h5',save_best_only=True)\n",
    "tb_cb = keras.callbacks.TensorBoard(get_run_logdir(),)\n",
    "\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs = 100, validation_data = (X_val,y_val),callbacks = [early_cb,save_cb,tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5159 - accuracy: 0.4664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.515872836112976, 0.46639999747276306]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) With Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (32,32,3),name = 'flat_in'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for i in range(20): #add 20 layers\n",
    "    model.add(keras.layers.Dense(100,name = f'dense_{i}',kernel_initializer = 'HeNormal'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "\n",
    "model.add(keras.layers.Dense(10,activation = 'softmax',name = 'dense_out'))\n",
    "\n",
    "my_opt = keras.optimizers.Nadam(learning_rate = 5e-5)\n",
    "model.compile(optimizer = my_opt, loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 42s 21ms/step - loss: 2.0398 - accuracy: 0.2678 - val_loss: 1.7597 - val_accuracy: 0.3670\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.7857 - accuracy: 0.3593 - val_loss: 1.6486 - val_accuracy: 0.4146\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.6949 - accuracy: 0.3952 - val_loss: 1.6025 - val_accuracy: 0.4254\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.6384 - accuracy: 0.4168 - val_loss: 1.5427 - val_accuracy: 0.4510\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5954 - accuracy: 0.4309 - val_loss: 1.4998 - val_accuracy: 0.4638\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5569 - accuracy: 0.4459 - val_loss: 1.4819 - val_accuracy: 0.4746\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5255 - accuracy: 0.4574 - val_loss: 1.4651 - val_accuracy: 0.4826\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4974 - accuracy: 0.4674 - val_loss: 1.4612 - val_accuracy: 0.4736\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4760 - accuracy: 0.4772 - val_loss: 1.4432 - val_accuracy: 0.4822\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4571 - accuracy: 0.4842 - val_loss: 1.4232 - val_accuracy: 0.4950\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.4348 - accuracy: 0.4899 - val_loss: 1.4207 - val_accuracy: 0.4902\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.4177 - accuracy: 0.4982 - val_loss: 1.4193 - val_accuracy: 0.4942\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.4009 - accuracy: 0.5014 - val_loss: 1.4152 - val_accuracy: 0.4948\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 27s 20ms/step - loss: 1.3850 - accuracy: 0.5086 - val_loss: 1.3972 - val_accuracy: 0.5094\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3670 - accuracy: 0.5149 - val_loss: 1.4156 - val_accuracy: 0.5070\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 1.3616 - accuracy: 0.5167 - val_loss: 1.3884 - val_accuracy: 0.4990\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.3482 - accuracy: 0.5212 - val_loss: 1.3919 - val_accuracy: 0.5102\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 1.3302 - accuracy: 0.5294 - val_loss: 1.3711 - val_accuracy: 0.5182\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 27s 20ms/step - loss: 1.3176 - accuracy: 0.5332 - val_loss: 1.3694 - val_accuracy: 0.5160\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3091 - accuracy: 0.5358 - val_loss: 1.3760 - val_accuracy: 0.5106\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3013 - accuracy: 0.5371 - val_loss: 1.3829 - val_accuracy: 0.5156\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2869 - accuracy: 0.5436 - val_loss: 1.3780 - val_accuracy: 0.5146\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2760 - accuracy: 0.5489 - val_loss: 1.3810 - val_accuracy: 0.5098\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2627 - accuracy: 0.5508 - val_loss: 1.3678 - val_accuracy: 0.5228\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2574 - accuracy: 0.5540 - val_loss: 1.3826 - val_accuracy: 0.5136\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2532 - accuracy: 0.5540 - val_loss: 1.3691 - val_accuracy: 0.5226\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2384 - accuracy: 0.5599 - val_loss: 1.3735 - val_accuracy: 0.5196\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2343 - accuracy: 0.5633 - val_loss: 1.3753 - val_accuracy: 0.5158\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2244 - accuracy: 0.5662 - val_loss: 1.3649 - val_accuracy: 0.5248\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2173 - accuracy: 0.5669 - val_loss: 1.3668 - val_accuracy: 0.5196\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2037 - accuracy: 0.5742 - val_loss: 1.3811 - val_accuracy: 0.5302\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1990 - accuracy: 0.5751 - val_loss: 1.3725 - val_accuracy: 0.5226\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1916 - accuracy: 0.5762 - val_loss: 1.3674 - val_accuracy: 0.5264\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1842 - accuracy: 0.5783 - val_loss: 1.3700 - val_accuracy: 0.5276\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1799 - accuracy: 0.5800 - val_loss: 1.3734 - val_accuracy: 0.5278\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1702 - accuracy: 0.5838 - val_loss: 1.3677 - val_accuracy: 0.5178\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1600 - accuracy: 0.5872 - val_loss: 1.3619 - val_accuracy: 0.5290\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1581 - accuracy: 0.5893 - val_loss: 1.3763 - val_accuracy: 0.5278\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1477 - accuracy: 0.5901 - val_loss: 1.3753 - val_accuracy: 0.5258\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1364 - accuracy: 0.5980 - val_loss: 1.3839 - val_accuracy: 0.5254\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1326 - accuracy: 0.5992 - val_loss: 1.3766 - val_accuracy: 0.5284\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1278 - accuracy: 0.5965 - val_loss: 1.3847 - val_accuracy: 0.5274\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1228 - accuracy: 0.6005 - val_loss: 1.3933 - val_accuracy: 0.5268\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1162 - accuracy: 0.6016 - val_loss: 1.3989 - val_accuracy: 0.5184\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1095 - accuracy: 0.6026 - val_loss: 1.3915 - val_accuracy: 0.5272\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1083 - accuracy: 0.6081 - val_loss: 1.3785 - val_accuracy: 0.5284\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 1.0956 - accuracy: 0.6114 - val_loss: 1.3924 - val_accuracy: 0.5254\n"
     ]
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)\n",
    "save_cb = keras.callbacks.ModelCheckpoint('my_cifar10_batch_norm.h5',save_best_only=True)\n",
    "tb_cb = keras.callbacks.TensorBoard(get_run_logdir(),)\n",
    "\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs = 100, validation_data = (X_val,y_val),callbacks = [early_cb,save_cb,tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 1.3625 - accuracy: 0.5175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.362518072128296, 0.5174999833106995]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) SELU instead of Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the datasets for SELU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = np.mean(X_train,axis=0)\n",
    "X_std = np.std(X_train,axis=0)\n",
    "\n",
    "X_train_selu = (X_train - X_mean)/X_std\n",
    "\n",
    "X_val_selu = (X_val - X_mean)/X_std\n",
    "\n",
    "X_test_selu = (X_test - X_mean)/X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lecun = tf.keras.initializers.LecunUniform()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (32,32,3),name = 'flat_in'))\n",
    "\n",
    "for i in range(20): #add 20 layers\n",
    "    model.add(keras.layers.Dense(100,activation = 'elu',name = f'dense_{i}',kernel_initializer = init_lecun))\n",
    "\n",
    "model.add(keras.layers.Dense(10,activation = 'softmax',name = 'dense_out'))\n",
    "\n",
    "my_opt = keras.optimizers.Nadam(learning_rate = 5e-5)\n",
    "model.compile(optimizer = my_opt, loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 22s 12ms/step - loss: 1.7343 - accuracy: 0.3767 - val_loss: 1.5817 - val_accuracy: 0.4322\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.5036 - accuracy: 0.4652 - val_loss: 1.5100 - val_accuracy: 0.4584\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4074 - accuracy: 0.4987 - val_loss: 1.4715 - val_accuracy: 0.4768\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3417 - accuracy: 0.5250 - val_loss: 1.4399 - val_accuracy: 0.4944\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2868 - accuracy: 0.5439 - val_loss: 1.4114 - val_accuracy: 0.5006\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2403 - accuracy: 0.5626 - val_loss: 1.4274 - val_accuracy: 0.4972\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1995 - accuracy: 0.5742 - val_loss: 1.4104 - val_accuracy: 0.5114\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1632 - accuracy: 0.5887 - val_loss: 1.4163 - val_accuracy: 0.5040\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1296 - accuracy: 0.6033 - val_loss: 1.4353 - val_accuracy: 0.5044\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0982 - accuracy: 0.6124 - val_loss: 1.4231 - val_accuracy: 0.5070\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0697 - accuracy: 0.6257 - val_loss: 1.4325 - val_accuracy: 0.5128\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0408 - accuracy: 0.6338 - val_loss: 1.4472 - val_accuracy: 0.5082\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0128 - accuracy: 0.6435 - val_loss: 1.4526 - val_accuracy: 0.5128\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9899 - accuracy: 0.6520 - val_loss: 1.4496 - val_accuracy: 0.5128\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9621 - accuracy: 0.6636 - val_loss: 1.5174 - val_accuracy: 0.5044\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9398 - accuracy: 0.6704 - val_loss: 1.4999 - val_accuracy: 0.5184\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9155 - accuracy: 0.6815 - val_loss: 1.5011 - val_accuracy: 0.5140\n"
     ]
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)\n",
    "save_cb = keras.callbacks.ModelCheckpoint('my_cifar10_SELU.h5',save_best_only=True)\n",
    "tb_cb = keras.callbacks.TensorBoard(get_run_logdir(),)\n",
    "\n",
    "\n",
    "history = model.fit(X_train_selu,y_train,epochs = 100, validation_data = (X_val_selu,y_val),callbacks = [early_cb,save_cb,tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4081 - accuracy: 0.5043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.408065676689148, 0.5042999982833862]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_selu,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Drop out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Alpha Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (32,32,3),name = 'flat_in'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for i in range(20): #add 20 layers\n",
    "    model.add(keras.layers.Dense(100,name = f'dense_{i}',kernel_initializer = 'HeNormal'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(0.1,seed = 42,name = f'drop_{i}'))\n",
    "model.add(keras.layers.Dense(10,activation = 'softmax',name = 'dense_out'))\n",
    "\n",
    "my_opt = keras.optimizers.Nadam(learning_rate = 5e-5)\n",
    "model.compile(optimizer = my_opt, loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 41s 20ms/step - loss: 2.2367 - accuracy: 0.2325 - val_loss: 1.7517 - val_accuracy: 0.3688\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.9578 - accuracy: 0.3185 - val_loss: 1.6442 - val_accuracy: 0.4148\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.8501 - accuracy: 0.3557 - val_loss: 1.5829 - val_accuracy: 0.4446\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.7759 - accuracy: 0.3816 - val_loss: 1.5484 - val_accuracy: 0.4562\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.7152 - accuracy: 0.3997 - val_loss: 1.5022 - val_accuracy: 0.4686\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.6684 - accuracy: 0.4166 - val_loss: 1.4924 - val_accuracy: 0.4716\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.6271 - accuracy: 0.4305 - val_loss: 1.4669 - val_accuracy: 0.4870\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5936 - accuracy: 0.4388 - val_loss: 1.4569 - val_accuracy: 0.4858\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5625 - accuracy: 0.4532 - val_loss: 1.4468 - val_accuracy: 0.4916\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5349 - accuracy: 0.4601 - val_loss: 1.4175 - val_accuracy: 0.4992\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.5157 - accuracy: 0.4688 - val_loss: 1.4304 - val_accuracy: 0.5018\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4887 - accuracy: 0.4782 - val_loss: 1.4114 - val_accuracy: 0.5088\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4681 - accuracy: 0.4839 - val_loss: 1.3961 - val_accuracy: 0.5134\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.4458 - accuracy: 0.4897 - val_loss: 1.4085 - val_accuracy: 0.5022\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.4271 - accuracy: 0.4986 - val_loss: 1.4349 - val_accuracy: 0.5008\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.4166 - accuracy: 0.5028 - val_loss: 1.3891 - val_accuracy: 0.5100\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4025 - accuracy: 0.5060 - val_loss: 1.3878 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3826 - accuracy: 0.5130 - val_loss: 1.3816 - val_accuracy: 0.5206\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3643 - accuracy: 0.5211 - val_loss: 1.3733 - val_accuracy: 0.5222\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3589 - accuracy: 0.5220 - val_loss: 1.3846 - val_accuracy: 0.5206\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3395 - accuracy: 0.5301 - val_loss: 1.3811 - val_accuracy: 0.5158\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3274 - accuracy: 0.5314 - val_loss: 1.3755 - val_accuracy: 0.5220\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3218 - accuracy: 0.5332 - val_loss: 1.3786 - val_accuracy: 0.5204\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3069 - accuracy: 0.5403 - val_loss: 1.3736 - val_accuracy: 0.5226\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2947 - accuracy: 0.5477 - val_loss: 1.3833 - val_accuracy: 0.5244\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2855 - accuracy: 0.5512 - val_loss: 1.3826 - val_accuracy: 0.5318\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2727 - accuracy: 0.5552 - val_loss: 1.3888 - val_accuracy: 0.5286\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2654 - accuracy: 0.5588 - val_loss: 1.3919 - val_accuracy: 0.5254\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2562 - accuracy: 0.5594 - val_loss: 1.3897 - val_accuracy: 0.5278\n"
     ]
    }
   ],
   "source": [
    "early_cb = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)\n",
    "save_cb = keras.callbacks.ModelCheckpoint('my_cifar10_alpha_drop.h5',save_best_only=True)\n",
    "tb_cb = keras.callbacks.TensorBoard(get_run_logdir(),)\n",
    "\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs = 100, validation_data = (X_val,y_val),callbacks = [early_cb,save_cb,tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 1.4063 - accuracy: 0.5147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4062851667404175, 0.5146999955177307]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. MC Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas = np.stack([model(X_test,training = True) for _ in range(100)])\n",
    "y_preds = np.argmax(y_probas.mean(axis=0),axis=1)\n",
    "accuracy_score(y_preds,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) 1cycle Training Schedule"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5effdde1fd048803b3704d23bd87152bc8d30461613bdeefdecf9d4ac1d2da28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
