{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf,yf = fetch_california_housing(return_X_y= True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(Xf,yf,test_size = .2)\n",
    "X_test,X_val,y_test,y_val = train_test_split(X_test,y_test,test_size = .5)\n",
    "\n",
    "my_scaler = StandardScaler()\n",
    "X_train = my_scaler.fit_transform(X_train)\n",
    "X_test = my_scaler.transform(X_test)\n",
    "X_val = my_scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 8)\n",
      "(16512,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a Test NN to verify our Batch Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "516/516 [==============================] - 2s 3ms/step - loss: 1.0473 - val_loss: 0.6771\n",
      "Epoch 2/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5933 - val_loss: 0.5829\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5366 - val_loss: 0.5505\n",
      "Epoch 4/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5088 - val_loss: 0.5221\n",
      "Epoch 5/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4906 - val_loss: 0.5049\n",
      "Epoch 6/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4767 - val_loss: 0.4914\n",
      "Epoch 7/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4651 - val_loss: 0.4822\n",
      "Epoch 8/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4558 - val_loss: 0.4712\n",
      "Epoch 9/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4481 - val_loss: 0.4623\n",
      "Epoch 10/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4413 - val_loss: 0.4557\n",
      "Epoch 11/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.4485\n",
      "Epoch 12/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4304 - val_loss: 0.4432\n",
      "Epoch 13/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4251 - val_loss: 0.4381\n",
      "Epoch 14/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4213 - val_loss: 0.4329\n",
      "Epoch 15/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4292\n",
      "Epoch 16/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4135 - val_loss: 0.4255\n",
      "Epoch 17/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4101 - val_loss: 0.4187\n",
      "Epoch 18/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.4162\n",
      "Epoch 19/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4037 - val_loss: 0.4125\n",
      "Epoch 20/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4009 - val_loss: 0.4097\n",
      "Epoch 21/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4067\n",
      "Epoch 22/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3952 - val_loss: 0.4036\n",
      "Epoch 23/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.4018\n",
      "Epoch 24/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3901 - val_loss: 0.3977\n",
      "Epoch 25/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3876 - val_loss: 0.3953\n",
      "Epoch 26/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.3939\n",
      "Epoch 27/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.3921\n",
      "Epoch 28/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3873\n",
      "Epoch 29/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.3856\n",
      "Epoch 30/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.3850\n",
      "Epoch 31/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.3822\n",
      "Epoch 32/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.3794\n",
      "Epoch 33/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3791\n",
      "Epoch 34/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3666 - val_loss: 0.3747\n",
      "Epoch 35/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.3712\n",
      "Epoch 36/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3683\n",
      "Epoch 37/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3671\n",
      "Epoch 38/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3644\n",
      "Epoch 39/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3561 - val_loss: 0.3645\n",
      "Epoch 40/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3613\n",
      "Epoch 41/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3592\n",
      "Epoch 42/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3571\n",
      "Epoch 43/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3565\n",
      "Epoch 44/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3550\n",
      "Epoch 45/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3459 - val_loss: 0.3519\n",
      "Epoch 46/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3441 - val_loss: 0.3516\n",
      "Epoch 47/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.3502\n",
      "Epoch 48/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3505\n",
      "Epoch 49/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3480\n",
      "Epoch 50/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3456\n",
      "Epoch 51/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3366 - val_loss: 0.3457\n",
      "Epoch 52/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3354 - val_loss: 0.3461\n",
      "Epoch 53/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.3405\n",
      "Epoch 54/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3408\n",
      "Epoch 55/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3319 - val_loss: 0.3405\n",
      "Epoch 56/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3305 - val_loss: 0.3391\n",
      "Epoch 57/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3295 - val_loss: 0.3364\n",
      "Epoch 58/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3351\n",
      "Epoch 59/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3340\n",
      "Epoch 60/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.3336\n",
      "Epoch 61/100\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 0.3248 - val_loss: 0.3307\n",
      "Epoch 62/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3240 - val_loss: 0.3298\n",
      "Epoch 63/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3297\n",
      "Epoch 64/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3226 - val_loss: 0.3277\n",
      "Epoch 65/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3210 - val_loss: 0.3262\n",
      "Epoch 66/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3202 - val_loss: 0.3255\n",
      "Epoch 67/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3258\n",
      "Epoch 68/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3181 - val_loss: 0.3254\n",
      "Epoch 69/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3175 - val_loss: 0.3233\n",
      "Epoch 70/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3162 - val_loss: 0.3213\n",
      "Epoch 71/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3240\n",
      "Epoch 72/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3147 - val_loss: 0.3193\n",
      "Epoch 73/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3138 - val_loss: 0.3190\n",
      "Epoch 74/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3131 - val_loss: 0.3188\n",
      "Epoch 75/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.3176\n",
      "Epoch 76/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3110 - val_loss: 0.3194\n",
      "Epoch 77/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3105 - val_loss: 0.3155\n",
      "Epoch 78/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3092 - val_loss: 0.3147\n",
      "Epoch 79/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3087 - val_loss: 0.3149\n",
      "Epoch 80/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3087 - val_loss: 0.3134\n",
      "Epoch 81/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3072 - val_loss: 0.3150\n",
      "Epoch 82/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3068 - val_loss: 0.3122\n",
      "Epoch 83/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3066 - val_loss: 0.3108\n",
      "Epoch 84/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3059 - val_loss: 0.3104\n",
      "Epoch 85/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3049 - val_loss: 0.3145\n",
      "Epoch 86/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3043 - val_loss: 0.3100\n",
      "Epoch 87/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3037 - val_loss: 0.3106\n",
      "Epoch 88/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3087\n",
      "Epoch 89/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3026 - val_loss: 0.3079\n",
      "Epoch 90/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3026 - val_loss: 0.3096\n",
      "Epoch 91/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3015 - val_loss: 0.3053\n",
      "Epoch 92/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.3054\n",
      "Epoch 93/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3010 - val_loss: 0.3052\n",
      "Epoch 94/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3004 - val_loss: 0.3061\n",
      "Epoch 95/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2995 - val_loss: 0.3052\n",
      "Epoch 96/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2993 - val_loss: 0.3051\n",
      "Epoch 97/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2991 - val_loss: 0.3071\n",
      "Epoch 98/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2986 - val_loss: 0.3042\n",
      "Epoch 99/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2978 - val_loss: 0.3034\n",
      "Epoch 100/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2978 - val_loss: 0.3078\n"
     ]
    }
   ],
   "source": [
    "ref_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation='relu',input_shape = (8,)),\n",
    "    keras.layers.LayerNormalization(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10,verbose = 1, restore_best_weights = True)\n",
    "ref_model.compile(loss= 'mse',optimizer = keras.optimizers.SGD(learning_rate = 1e-3))\n",
    "ref_hist = ref_model.fit(X_train,y_train,epochs = 100, validation_data = (X_val,y_val),callbacks = [early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3103\n",
      "0.31030380725860596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ref_model.evaluate(X_test,y_test))\n",
    "pd.DataFrame(ref_hist.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a Custom Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayerNorm(keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self,X_input_shape):\n",
    "        self.alpha = self.add_weight(name = 'alpha',shape = X_input_shape[-1:], dtype = float, trainable = True, initializer = 'ones')\n",
    "        self.beta = self.add_weight(name = 'beta',shape = X_input_shape[-1:], dtype = float, trainable = True, initializer = 'zeros')\n",
    "        super().build(X_input_shape)\n",
    "\n",
    "        \n",
    "    def call(self,X):\n",
    "        self.my_mean = tf.reshape(tf.math.reduce_mean(X,axis=-1),(-1,1))\n",
    "        self.my_std = tf.reshape(tf.math.reduce_std(X,axis=-1),(-1,1)) \n",
    "    \n",
    "        return tf.divide(self.alpha*tf.subtract(X,self.my_mean),tf.sqrt(tf.square(self.my_std) + .001)) + self.beta\n",
    "\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return batch_input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "516/516 [==============================] - 2s 2ms/step - loss: 0.9020 - val_loss: 0.6255\n",
      "Epoch 2/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5513 - val_loss: 0.5550\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.5053 - val_loss: 0.5233\n",
      "Epoch 4/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4819 - val_loss: 0.4978\n",
      "Epoch 5/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4670 - val_loss: 0.4830\n",
      "Epoch 6/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4559 - val_loss: 0.4712\n",
      "Epoch 7/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4473 - val_loss: 0.4644\n",
      "Epoch 8/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4542\n",
      "Epoch 9/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 0.4490\n",
      "Epoch 10/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4309 - val_loss: 0.4436\n",
      "Epoch 11/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.4393\n",
      "Epoch 12/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4235 - val_loss: 0.4339\n",
      "Epoch 13/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4194 - val_loss: 0.4320\n",
      "Epoch 14/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.4276\n",
      "Epoch 15/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4135 - val_loss: 0.4254\n",
      "Epoch 16/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.4216\n",
      "Epoch 17/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4169\n",
      "Epoch 18/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.4153\n",
      "Epoch 19/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4028 - val_loss: 0.4121\n",
      "Epoch 20/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4113\n",
      "Epoch 21/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.4077\n",
      "Epoch 22/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.4066\n",
      "Epoch 23/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4038\n",
      "Epoch 24/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3917 - val_loss: 0.4015\n",
      "Epoch 25/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.3997\n",
      "Epoch 26/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.3984\n",
      "Epoch 27/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3857 - val_loss: 0.3971\n",
      "Epoch 28/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 0.3943\n",
      "Epoch 29/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.3931\n",
      "Epoch 30/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.3919\n",
      "Epoch 31/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3783 - val_loss: 0.3895\n",
      "Epoch 32/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.3869\n",
      "Epoch 33/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3873\n",
      "Epoch 34/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.3831\n",
      "Epoch 35/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.3799\n",
      "Epoch 36/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3777\n",
      "Epoch 37/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.3771\n",
      "Epoch 38/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3657 - val_loss: 0.3744\n",
      "Epoch 39/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3641 - val_loss: 0.3744\n",
      "Epoch 40/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3625 - val_loss: 0.3712\n",
      "Epoch 41/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.3708\n",
      "Epoch 42/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3677\n",
      "Epoch 43/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.3678\n",
      "Epoch 44/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3561 - val_loss: 0.3666\n",
      "Epoch 45/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3631\n",
      "Epoch 46/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3531 - val_loss: 0.3618\n",
      "Epoch 47/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.3604\n",
      "Epoch 48/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3628\n",
      "Epoch 49/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3574\n",
      "Epoch 50/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3559\n",
      "Epoch 51/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3461 - val_loss: 0.3557\n",
      "Epoch 52/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3560\n",
      "Epoch 53/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3436 - val_loss: 0.3508\n",
      "Epoch 54/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3426 - val_loss: 0.3514\n",
      "Epoch 55/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.3500\n",
      "Epoch 56/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3497\n",
      "Epoch 57/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3464\n",
      "Epoch 58/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3387 - val_loss: 0.3450\n",
      "Epoch 59/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3442\n",
      "Epoch 60/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3439\n",
      "Epoch 61/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3421\n",
      "Epoch 62/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.3415\n",
      "Epoch 63/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.3395\n",
      "Epoch 64/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3397\n",
      "Epoch 65/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.3384\n",
      "Epoch 66/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3385\n",
      "Epoch 67/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3312 - val_loss: 0.3391\n",
      "Epoch 68/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.3397\n",
      "Epoch 69/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3297 - val_loss: 0.3363\n",
      "Epoch 70/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3288 - val_loss: 0.3357\n",
      "Epoch 71/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3279 - val_loss: 0.3374\n",
      "Epoch 72/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3277 - val_loss: 0.3335\n",
      "Epoch 73/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3339\n",
      "Epoch 74/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.3339\n",
      "Epoch 75/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3259 - val_loss: 0.3328\n",
      "Epoch 76/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3346\n",
      "Epoch 77/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3320\n",
      "Epoch 78/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3238 - val_loss: 0.3328\n",
      "Epoch 79/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3236 - val_loss: 0.3309\n",
      "Epoch 80/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3234 - val_loss: 0.3306\n",
      "Epoch 81/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3221 - val_loss: 0.3331\n",
      "Epoch 82/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3220 - val_loss: 0.3279\n",
      "Epoch 83/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3217 - val_loss: 0.3278\n",
      "Epoch 84/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3212 - val_loss: 0.3284\n",
      "Epoch 85/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3205 - val_loss: 0.3312\n",
      "Epoch 86/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3199 - val_loss: 0.3276\n",
      "Epoch 87/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3196 - val_loss: 0.3267\n",
      "Epoch 88/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3192 - val_loss: 0.3257\n",
      "Epoch 89/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3187 - val_loss: 0.3265\n",
      "Epoch 90/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3185 - val_loss: 0.3265\n",
      "Epoch 91/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3176 - val_loss: 0.3238\n",
      "Epoch 92/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3175 - val_loss: 0.3239\n",
      "Epoch 93/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3246\n",
      "Epoch 94/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3166 - val_loss: 0.3256\n",
      "Epoch 95/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3238\n",
      "Epoch 96/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3159 - val_loss: 0.3229\n",
      "Epoch 97/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3154 - val_loss: 0.3278\n",
      "Epoch 98/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3152 - val_loss: 0.3245\n",
      "Epoch 99/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3143 - val_loss: 0.3251\n",
      "Epoch 100/100\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.3143 - val_loss: 0.3280\n"
     ]
    }
   ],
   "source": [
    "my_model = keras.models.Sequential([\n",
    "     keras.layers.Dense(30,activation='relu',input_shape = (8,)),\n",
    "    CustomLayerNorm(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10,verbose = 1, restore_best_weights = True)\n",
    "my_model.compile(loss= 'mse',optimizer = keras.optimizers.SGD(learning_rate = 1e-3))\n",
    "my_hist = my_model.fit(X_train,y_train,epochs = 100, validation_data = (X_val,y_val),callbacks = [early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 0.3284\n",
      "0.3284273147583008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(my_model.evaluate(X_test,y_test))\n",
    "pd.DataFrame(my_hist.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify it at the style of the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.461345e-08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = keras.layers.LayerNormalization()\n",
    "custom = CustomLayerNorm()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(custom(X_train),default(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full,y_train_full),(X_test,y_test) = fashion_mnist.load_data()\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train_full,y_train_full,test_size=.2)\n",
    "\n",
    "X_train,X_val,X_test = X_train/255.,X_val/255.,X_test/255.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aiding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(epoch,iteration,total_iterations,mean_training_loss=[],mean_training_accuracy=[],mean_validation_loss = [],mean_validation_accuracy=[]):\n",
    "    tot_width = 100\n",
    "    done = (iteration * tot_width) // total_iterations\n",
    "    tbd = tot_width - done\n",
    "    \n",
    "    print(f'epoch: {epoch+1} - Current iteration: {iteration+1}       [{\"-\"*(done)}{\" \"*(tbd)}]',end = '\\r')\n",
    "    \n",
    "    if  mean_training_loss:\n",
    "        print(f'\\nMean Training Loss: {mean_training_loss :.4f}   Mean Training Accuracy: {mean_training_accuracy:.4f} || Mean Validation Loss: {mean_validation_loss:.4f}   Mean Validation Accuracy: {mean_validation_accuracy:.4f}\\n')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extraction(X,y,batch_size=32):\n",
    "    samp_indx = np.random.choice(X.shape[0],batch_size)\n",
    "    return X[samp_indx,:],y[samp_indx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(keras.models.Model):\n",
    "    def __init__(self,n_layers = 2, n_neurons = 1000, activation = None, **kwargs):\n",
    "        super().__init__(**kwargs)        \n",
    "        \n",
    "        self.hiddens = [keras.layers.Dense(n_neurons,activation = activation) for _ in range(n_layers)];\n",
    "        self.out = keras.layers.Dense(10,activation = 'softmax')\n",
    "        \n",
    "    def build(self,X_input_shape):\n",
    "        self.in_layer = keras.layers.Flatten(input_shape = X_input_shape[1:])\n",
    "        super().build(X_input_shape)\n",
    "        \n",
    "        \n",
    "    def call(self,X,training = None):\n",
    "        Z = self.in_layer(X)\n",
    "\n",
    "        for layer in self.hiddens:\n",
    "            Z = layer(Z)\n",
    "            \n",
    "        return self.out(Z)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 4096\n",
    "lr = .01\n",
    "momentum = .99\n",
    "layers = 1\n",
    "n_neurons = 100\n",
    "activation = 'relu'\n",
    "\n",
    "model = my_model(n_layers = layers, n_neurons= n_neurons, activation= activation)\n",
    "optimizer = keras.optimizers.Nadam(learning_rate = lr)\n",
    "#optimizer = keras.optimizers.RMSprop(learning_rate = lr, momentum = momentum)\n",
    "loss_function = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2475   Mean Training Accuracy: 0.9085 || Mean Validation Loss: 0.3268   Mean Validation Accuracy: 0.8850\n",
      "\n",
      "epoch: 1 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2775   Mean Training Accuracy: 0.8954 || Mean Validation Loss: 0.3526   Mean Validation Accuracy: 0.8730\n",
      "\n",
      "epoch: 2 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2971   Mean Training Accuracy: 0.8856 || Mean Validation Loss: 0.3750   Mean Validation Accuracy: 0.8665\n",
      "\n",
      "epoch: 3 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2705   Mean Training Accuracy: 0.8969 || Mean Validation Loss: 0.3486   Mean Validation Accuracy: 0.8752\n",
      "\n",
      "epoch: 4 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2538   Mean Training Accuracy: 0.9046 || Mean Validation Loss: 0.3376   Mean Validation Accuracy: 0.8785\n",
      "\n",
      "epoch: 5 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2659   Mean Training Accuracy: 0.8999 || Mean Validation Loss: 0.3470   Mean Validation Accuracy: 0.8772\n",
      "\n",
      "epoch: 6 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2658   Mean Training Accuracy: 0.9004 || Mean Validation Loss: 0.3491   Mean Validation Accuracy: 0.8744\n",
      "\n",
      "epoch: 7 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2393   Mean Training Accuracy: 0.9109 || Mean Validation Loss: 0.3256   Mean Validation Accuracy: 0.8861\n",
      "\n",
      "epoch: 8 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2569   Mean Training Accuracy: 0.9045 || Mean Validation Loss: 0.3433   Mean Validation Accuracy: 0.8791\n",
      "\n",
      "epoch: 9 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2668   Mean Training Accuracy: 0.8993 || Mean Validation Loss: 0.3491   Mean Validation Accuracy: 0.8731\n",
      "\n",
      "epoch: 10 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2741   Mean Training Accuracy: 0.8975 || Mean Validation Loss: 0.3588   Mean Validation Accuracy: 0.8728\n",
      "\n",
      "epoch: 11 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2426   Mean Training Accuracy: 0.9091 || Mean Validation Loss: 0.3316   Mean Validation Accuracy: 0.8856\n",
      "\n",
      "epoch: 12 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2425   Mean Training Accuracy: 0.9096 || Mean Validation Loss: 0.3294   Mean Validation Accuracy: 0.8848\n",
      "\n",
      "epoch: 13 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2548   Mean Training Accuracy: 0.9052 || Mean Validation Loss: 0.3452   Mean Validation Accuracy: 0.8785\n",
      "\n",
      "epoch: 14 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2407   Mean Training Accuracy: 0.9107 || Mean Validation Loss: 0.3258   Mean Validation Accuracy: 0.8857\n",
      "\n",
      "epoch: 15 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2301   Mean Training Accuracy: 0.9154 || Mean Validation Loss: 0.3259   Mean Validation Accuracy: 0.8878\n",
      "\n",
      "epoch: 16 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2652   Mean Training Accuracy: 0.8996 || Mean Validation Loss: 0.3560   Mean Validation Accuracy: 0.8722\n",
      "\n",
      "epoch: 17 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2452   Mean Training Accuracy: 0.9081 || Mean Validation Loss: 0.3367   Mean Validation Accuracy: 0.8810\n",
      "\n",
      "epoch: 18 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2581   Mean Training Accuracy: 0.9037 || Mean Validation Loss: 0.3445   Mean Validation Accuracy: 0.8798\n",
      "\n",
      "epoch: 19 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.3042   Mean Training Accuracy: 0.8822 || Mean Validation Loss: 0.4011   Mean Validation Accuracy: 0.8579\n",
      "\n",
      "epoch: 20 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2708   Mean Training Accuracy: 0.8964 || Mean Validation Loss: 0.3637   Mean Validation Accuracy: 0.8719\n",
      "\n",
      "epoch: 21 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2556   Mean Training Accuracy: 0.9039 || Mean Validation Loss: 0.3499   Mean Validation Accuracy: 0.8797\n",
      "\n",
      "epoch: 22 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2465   Mean Training Accuracy: 0.9088 || Mean Validation Loss: 0.3420   Mean Validation Accuracy: 0.8810\n",
      "\n",
      "epoch: 23 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2249   Mean Training Accuracy: 0.9171 || Mean Validation Loss: 0.3245   Mean Validation Accuracy: 0.8882\n",
      "\n",
      "epoch: 24 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2654   Mean Training Accuracy: 0.9001 || Mean Validation Loss: 0.3636   Mean Validation Accuracy: 0.8728\n",
      "\n",
      "epoch: 25 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2568   Mean Training Accuracy: 0.9039 || Mean Validation Loss: 0.3463   Mean Validation Accuracy: 0.8754\n",
      "\n",
      "epoch: 26 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2584   Mean Training Accuracy: 0.9026 || Mean Validation Loss: 0.3505   Mean Validation Accuracy: 0.8763\n",
      "\n",
      "epoch: 27 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2518   Mean Training Accuracy: 0.9049 || Mean Validation Loss: 0.3520   Mean Validation Accuracy: 0.8790\n",
      "\n",
      "epoch: 28 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2377   Mean Training Accuracy: 0.9102 || Mean Validation Loss: 0.3450   Mean Validation Accuracy: 0.8802\n",
      "\n",
      "epoch: 29 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2637   Mean Training Accuracy: 0.9015 || Mean Validation Loss: 0.3630   Mean Validation Accuracy: 0.8765\n",
      "\n",
      "epoch: 30 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2295   Mean Training Accuracy: 0.9147 || Mean Validation Loss: 0.3327   Mean Validation Accuracy: 0.8872\n",
      "\n",
      "epoch: 31 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2494   Mean Training Accuracy: 0.9065 || Mean Validation Loss: 0.3462   Mean Validation Accuracy: 0.8797\n",
      "\n",
      "epoch: 32 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2317   Mean Training Accuracy: 0.9130 || Mean Validation Loss: 0.3374   Mean Validation Accuracy: 0.8846\n",
      "\n",
      "epoch: 33 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2318   Mean Training Accuracy: 0.9126 || Mean Validation Loss: 0.3415   Mean Validation Accuracy: 0.8827\n",
      "\n",
      "epoch: 34 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2256   Mean Training Accuracy: 0.9159 || Mean Validation Loss: 0.3336   Mean Validation Accuracy: 0.8865\n",
      "\n",
      "epoch: 35 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2374   Mean Training Accuracy: 0.9101 || Mean Validation Loss: 0.3470   Mean Validation Accuracy: 0.8833\n",
      "\n",
      "epoch: 36 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2314   Mean Training Accuracy: 0.9138 || Mean Validation Loss: 0.3446   Mean Validation Accuracy: 0.8851\n",
      "\n",
      "epoch: 37 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2394   Mean Training Accuracy: 0.9100 || Mean Validation Loss: 0.3469   Mean Validation Accuracy: 0.8795\n",
      "\n",
      "epoch: 38 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2374   Mean Training Accuracy: 0.9112 || Mean Validation Loss: 0.3531   Mean Validation Accuracy: 0.8797\n",
      "\n",
      "epoch: 39 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2144   Mean Training Accuracy: 0.9208 || Mean Validation Loss: 0.3301   Mean Validation Accuracy: 0.8877\n",
      "\n",
      "epoch: 40 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2528   Mean Training Accuracy: 0.9030 || Mean Validation Loss: 0.3676   Mean Validation Accuracy: 0.8735\n",
      "\n",
      "epoch: 41 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2224   Mean Training Accuracy: 0.9184 || Mean Validation Loss: 0.3422   Mean Validation Accuracy: 0.8845\n",
      "\n",
      "epoch: 42 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2745   Mean Training Accuracy: 0.8944 || Mean Validation Loss: 0.3863   Mean Validation Accuracy: 0.8668\n",
      "\n",
      "epoch: 43 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2340   Mean Training Accuracy: 0.9134 || Mean Validation Loss: 0.3533   Mean Validation Accuracy: 0.8839\n",
      "\n",
      "epoch: 44 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2149   Mean Training Accuracy: 0.9210 || Mean Validation Loss: 0.3304   Mean Validation Accuracy: 0.8893\n",
      "\n",
      "epoch: 45 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2616   Mean Training Accuracy: 0.9000 || Mean Validation Loss: 0.3863   Mean Validation Accuracy: 0.8678\n",
      "\n",
      "epoch: 46 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2198   Mean Training Accuracy: 0.9173 || Mean Validation Loss: 0.3450   Mean Validation Accuracy: 0.8835\n",
      "\n",
      "epoch: 47 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2232   Mean Training Accuracy: 0.9152 || Mean Validation Loss: 0.3433   Mean Validation Accuracy: 0.8845\n",
      "\n",
      "epoch: 48 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2212   Mean Training Accuracy: 0.9181 || Mean Validation Loss: 0.3463   Mean Validation Accuracy: 0.8855\n",
      "\n",
      "epoch: 49 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2300   Mean Training Accuracy: 0.9116 || Mean Validation Loss: 0.3516   Mean Validation Accuracy: 0.8803\n",
      "\n",
      "epoch: 50 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2455   Mean Training Accuracy: 0.9073 || Mean Validation Loss: 0.3717   Mean Validation Accuracy: 0.8755\n",
      "\n",
      "epoch: 51 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2277   Mean Training Accuracy: 0.9147 || Mean Validation Loss: 0.3511   Mean Validation Accuracy: 0.8837\n",
      "\n",
      "epoch: 52 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2192   Mean Training Accuracy: 0.9183 || Mean Validation Loss: 0.3461   Mean Validation Accuracy: 0.8838\n",
      "\n",
      "epoch: 53 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2156   Mean Training Accuracy: 0.9191 || Mean Validation Loss: 0.3488   Mean Validation Accuracy: 0.8842\n",
      "\n",
      "epoch: 54 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2303   Mean Training Accuracy: 0.9141 || Mean Validation Loss: 0.3571   Mean Validation Accuracy: 0.8802\n",
      "\n",
      "epoch: 55 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2106   Mean Training Accuracy: 0.9214 || Mean Validation Loss: 0.3460   Mean Validation Accuracy: 0.8859\n",
      "\n",
      "epoch: 56 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2257   Mean Training Accuracy: 0.9155 || Mean Validation Loss: 0.3525   Mean Validation Accuracy: 0.8798\n",
      "\n",
      "epoch: 57 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.3050   Mean Training Accuracy: 0.8849 || Mean Validation Loss: 0.4289   Mean Validation Accuracy: 0.8592\n",
      "\n",
      "epoch: 58 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2254   Mean Training Accuracy: 0.9149 || Mean Validation Loss: 0.3487   Mean Validation Accuracy: 0.8833\n",
      "\n",
      "epoch: 59 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2173   Mean Training Accuracy: 0.9183 || Mean Validation Loss: 0.3505   Mean Validation Accuracy: 0.8820\n",
      "\n",
      "epoch: 60 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2141   Mean Training Accuracy: 0.9204 || Mean Validation Loss: 0.3439   Mean Validation Accuracy: 0.8862\n",
      "\n",
      "epoch: 61 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2288   Mean Training Accuracy: 0.9136 || Mean Validation Loss: 0.3545   Mean Validation Accuracy: 0.8799\n",
      "\n",
      "epoch: 62 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2501   Mean Training Accuracy: 0.9031 || Mean Validation Loss: 0.3817   Mean Validation Accuracy: 0.8664\n",
      "\n",
      "epoch: 63 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2184   Mean Training Accuracy: 0.9174 || Mean Validation Loss: 0.3531   Mean Validation Accuracy: 0.8822\n",
      "\n",
      "epoch: 64 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2348   Mean Training Accuracy: 0.9115 || Mean Validation Loss: 0.3658   Mean Validation Accuracy: 0.8764\n",
      "\n",
      "epoch: 65 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2241   Mean Training Accuracy: 0.9153 || Mean Validation Loss: 0.3607   Mean Validation Accuracy: 0.8778\n",
      "\n",
      "epoch: 66 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2757   Mean Training Accuracy: 0.8953 || Mean Validation Loss: 0.4020   Mean Validation Accuracy: 0.8642\n",
      "\n",
      "epoch: 67 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2184   Mean Training Accuracy: 0.9186 || Mean Validation Loss: 0.3550   Mean Validation Accuracy: 0.8810\n",
      "\n",
      "epoch: 68 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2136   Mean Training Accuracy: 0.9209 || Mean Validation Loss: 0.3415   Mean Validation Accuracy: 0.8856\n",
      "\n",
      "epoch: 69 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1971   Mean Training Accuracy: 0.9276 || Mean Validation Loss: 0.3387   Mean Validation Accuracy: 0.8882\n",
      "\n",
      "epoch: 70 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2464   Mean Training Accuracy: 0.9042 || Mean Validation Loss: 0.3850   Mean Validation Accuracy: 0.8720\n",
      "\n",
      "epoch: 71 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2060   Mean Training Accuracy: 0.9232 || Mean Validation Loss: 0.3530   Mean Validation Accuracy: 0.8848\n",
      "\n",
      "epoch: 72 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2130   Mean Training Accuracy: 0.9200 || Mean Validation Loss: 0.3529   Mean Validation Accuracy: 0.8841\n",
      "\n",
      "epoch: 73 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1978   Mean Training Accuracy: 0.9272 || Mean Validation Loss: 0.3451   Mean Validation Accuracy: 0.8877\n",
      "\n",
      "epoch: 74 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2281   Mean Training Accuracy: 0.9151 || Mean Validation Loss: 0.3610   Mean Validation Accuracy: 0.8791\n",
      "\n",
      "epoch: 75 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2003   Mean Training Accuracy: 0.9245 || Mean Validation Loss: 0.3478   Mean Validation Accuracy: 0.8863\n",
      "\n",
      "epoch: 76 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2133   Mean Training Accuracy: 0.9205 || Mean Validation Loss: 0.3552   Mean Validation Accuracy: 0.8815\n",
      "\n",
      "epoch: 77 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2056   Mean Training Accuracy: 0.9237 || Mean Validation Loss: 0.3500   Mean Validation Accuracy: 0.8857\n",
      "\n",
      "epoch: 78 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1941   Mean Training Accuracy: 0.9278 || Mean Validation Loss: 0.3466   Mean Validation Accuracy: 0.8897\n",
      "\n",
      "epoch: 79 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2161   Mean Training Accuracy: 0.9191 || Mean Validation Loss: 0.3682   Mean Validation Accuracy: 0.8801\n",
      "\n",
      "epoch: 80 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2602   Mean Training Accuracy: 0.8978 || Mean Validation Loss: 0.4081   Mean Validation Accuracy: 0.8613\n",
      "\n",
      "epoch: 81 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1861   Mean Training Accuracy: 0.9304 || Mean Validation Loss: 0.3423   Mean Validation Accuracy: 0.8904\n",
      "\n",
      "epoch: 82 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1920   Mean Training Accuracy: 0.9296 || Mean Validation Loss: 0.3425   Mean Validation Accuracy: 0.8907\n",
      "\n",
      "epoch: 83 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2954   Mean Training Accuracy: 0.8969 || Mean Validation Loss: 0.4500   Mean Validation Accuracy: 0.8646\n",
      "\n",
      "epoch: 84 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1925   Mean Training Accuracy: 0.9284 || Mean Validation Loss: 0.3531   Mean Validation Accuracy: 0.8878\n",
      "\n",
      "epoch: 85 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1918   Mean Training Accuracy: 0.9286 || Mean Validation Loss: 0.3488   Mean Validation Accuracy: 0.8886\n",
      "\n",
      "epoch: 86 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2122   Mean Training Accuracy: 0.9207 || Mean Validation Loss: 0.3710   Mean Validation Accuracy: 0.8807\n",
      "\n",
      "epoch: 87 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2129   Mean Training Accuracy: 0.9188 || Mean Validation Loss: 0.3607   Mean Validation Accuracy: 0.8812\n",
      "\n",
      "epoch: 88 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2176   Mean Training Accuracy: 0.9172 || Mean Validation Loss: 0.3765   Mean Validation Accuracy: 0.8792\n",
      "\n",
      "epoch: 89 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2012   Mean Training Accuracy: 0.9250 || Mean Validation Loss: 0.3562   Mean Validation Accuracy: 0.8856\n",
      "\n",
      "epoch: 90 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1899   Mean Training Accuracy: 0.9304 || Mean Validation Loss: 0.3567   Mean Validation Accuracy: 0.8878\n",
      "\n",
      "epoch: 91 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1866   Mean Training Accuracy: 0.9296 || Mean Validation Loss: 0.3526   Mean Validation Accuracy: 0.8882\n",
      "\n",
      "epoch: 92 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2069   Mean Training Accuracy: 0.9220 || Mean Validation Loss: 0.3713   Mean Validation Accuracy: 0.8792\n",
      "\n",
      "epoch: 93 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2010   Mean Training Accuracy: 0.9239 || Mean Validation Loss: 0.3645   Mean Validation Accuracy: 0.8855\n",
      "\n",
      "epoch: 94 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2168   Mean Training Accuracy: 0.9189 || Mean Validation Loss: 0.3809   Mean Validation Accuracy: 0.8827\n",
      "\n",
      "epoch: 95 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2083   Mean Training Accuracy: 0.9212 || Mean Validation Loss: 0.3820   Mean Validation Accuracy: 0.8826\n",
      "\n",
      "epoch: 96 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1911   Mean Training Accuracy: 0.9291 || Mean Validation Loss: 0.3584   Mean Validation Accuracy: 0.8856\n",
      "\n",
      "epoch: 97 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.2162   Mean Training Accuracy: 0.9170 || Mean Validation Loss: 0.3854   Mean Validation Accuracy: 0.8766\n",
      "\n",
      "epoch: 98 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1995   Mean Training Accuracy: 0.9246 || Mean Validation Loss: 0.3691   Mean Validation Accuracy: 0.8842\n",
      "\n",
      "epoch: 99 - Current iteration: 10       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.1931   Mean Training Accuracy: 0.9281 || Mean Validation Loss: 0.3694   Mean Validation Accuracy: 0.8833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = len(X_train) //batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(iterations):\n",
    "        X_batch,y_batch = batch_extraction(X_train,y_train,batch_size = batch_size)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch,training = True)\n",
    "            loss = loss_function(y_batch,y_pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss,model.trainable_variables) #backprop\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_variables)) #update parameters\n",
    "        \n",
    "        print_info(epoch,iter,iterations)\n",
    "        \n",
    "    ## Validation Metrics\n",
    "    y_pred_train  = model(X_train,training = False)\n",
    "    train_loss = loss_function(y_train,y_pred_train)\n",
    "    train_accuracy = accuracy_score(y_train,np.argmax(y_pred_train,axis=1))\n",
    "        \n",
    "    ## Validation Metrics\n",
    "    y_pred_val  = model(X_val,training = False)\n",
    "    val_loss = loss_function(y_val,y_pred_val)\n",
    "    val_accuracy = accuracy_score(y_val,np.argmax(y_pred_val,axis=1))\n",
    "    \n",
    "    print_info(epoch,iter,iterations,train_loss,train_accuracy,val_loss,val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8734, Testing loss: 0.417889267206192\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test,np.argmax(y_test_pred,axis=1))\n",
    "test_loss = loss_function(y_test,y_test_pred)\n",
    "\n",
    "print(f'Testing accuracy: {test_accuracy}, Testing loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veriying with a pre-defined Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 2s 54ms/step - loss: 1.9462 - val_loss: 1.1900\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.8555 - val_loss: 0.7086\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6904 - val_loss: 0.6475\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.6051 - val_loss: 0.5748\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5809 - val_loss: 0.5751\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.5396 - val_loss: 0.5135\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.5396 - val_loss: 0.5562\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.4927 - val_loss: 0.5076\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.4767 - val_loss: 0.4671\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.4693 - val_loss: 0.4989\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.4618 - val_loss: 0.4494\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.4361 - val_loss: 0.4565\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.4258 - val_loss: 0.4156\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.4049 - val_loss: 0.5066\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.4317 - val_loss: 0.4940\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.4062 - val_loss: 0.4052\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.4014 - val_loss: 0.4603\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3896 - val_loss: 0.3951\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3890 - val_loss: 0.3972\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3899 - val_loss: 0.3805\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3783 - val_loss: 0.4186\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3533 - val_loss: 0.4119\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3808 - val_loss: 0.3692\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3498 - val_loss: 0.3995\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3677 - val_loss: 0.3767\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.3618 - val_loss: 0.4909\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3556 - val_loss: 0.3729\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3409 - val_loss: 0.3635\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3327 - val_loss: 0.4215\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3510 - val_loss: 0.3726\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3321 - val_loss: 0.3754\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3341 - val_loss: 0.3472\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.3240 - val_loss: 0.3657\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3248 - val_loss: 0.3632\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3293 - val_loss: 0.3725\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.3167 - val_loss: 0.3628\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3104 - val_loss: 0.3609\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3136 - val_loss: 0.3510\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2982 - val_loss: 0.3364\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3154 - val_loss: 0.3395\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3125 - val_loss: 0.3433\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2941 - val_loss: 0.3521\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2943 - val_loss: 0.3653\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.2924 - val_loss: 0.4921\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3335 - val_loss: 0.3205\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2826 - val_loss: 0.3272\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2971 - val_loss: 0.3509\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.5951 - val_loss: 1.0442\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 8.2337 - val_loss: 0.9914\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.7323 - val_loss: 0.5888\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.5271 - val_loss: 0.5202\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.4780 - val_loss: 0.4839\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.4581 - val_loss: 0.4848\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.4533 - val_loss: 0.4519\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.4324 - val_loss: 0.4470\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.4084 - val_loss: 0.4345\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.4032 - val_loss: 0.4425\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3980 - val_loss: 0.4161\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3958 - val_loss: 0.4097\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3757 - val_loss: 0.4191\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3765 - val_loss: 0.4005\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3757 - val_loss: 0.4432\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3754 - val_loss: 0.3848\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3634 - val_loss: 0.3966\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3553 - val_loss: 0.3837\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3594 - val_loss: 0.3777\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3444 - val_loss: 0.3851\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3555 - val_loss: 0.3703\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3509 - val_loss: 0.3693\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3412 - val_loss: 0.3723\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3348 - val_loss: 0.3693\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3459 - val_loss: 0.3660\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3357 - val_loss: 0.3651\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3282 - val_loss: 0.3675\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3246 - val_loss: 0.3647\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3271 - val_loss: 0.3771\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3253 - val_loss: 0.3737\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3184 - val_loss: 0.3797\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3131 - val_loss: 0.3533\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3316 - val_loss: 0.3816\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3204 - val_loss: 0.3844\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3229 - val_loss: 0.3516\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3192 - val_loss: 0.3515\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3211 - val_loss: 0.3634\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.3066 - val_loss: 0.3759\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3068 - val_loss: 0.3515\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3107 - val_loss: 0.3678\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2987 - val_loss: 0.3819\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3013 - val_loss: 0.3503\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3046 - val_loss: 0.3568\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3061 - val_loss: 0.3480\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3080 - val_loss: 0.3601\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2918 - val_loss: 0.3553\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2928 - val_loss: 0.3367\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.3032 - val_loss: 0.3668\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2950 - val_loss: 0.3702\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3001 - val_loss: 0.3470\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.2958 - val_loss: 0.3419\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2906 - val_loss: 0.3428\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.2968 - val_loss: 0.3357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf8c7836a0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(100,activation = 'relu'),\n",
    "    keras.layers.Dense(10,activation = 'softmax')\n",
    "])\n",
    "\n",
    "ref_model.compile(loss = 'sparse_categorical_crossentropy', optimizer = keras.optimizers.Nadam(learning_rate = .01))#, metrics = [keras.metrics.Accuracy()])\n",
    "ref_model.fit(X_train,y_train, batch_size = 4096,epochs = 100, validation_data = (X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8715, Testing loss: 0.3653602600097656\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = ref_model.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test,np.argmax(y_test_pred,axis=1))\n",
    "test_loss = loss_function(y_test,y_test_pred)\n",
    "\n",
    "print(f'Testing accuracy: {test_accuracy}, Testing loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(keras.models.Model):\n",
    "    def __init__(self,n_layers = 2, n_neurons = 1000, activation = None, **kwargs):\n",
    "        super().__init__(**kwargs)        \n",
    "        \n",
    "        self.hiddens = [keras.layers.Dense(n_neurons,activation = activation, name = f'inner_{i}') for i in range(n_layers)];\n",
    "        self.out = keras.layers.Dense(10,activation = 'softmax',name = 'outer')\n",
    "        \n",
    "    def build(self,X_input_shape):\n",
    "        self.in_layer = keras.layers.Flatten(input_shape = X_input_shape[1:])\n",
    "        super().build(X_input_shape)\n",
    "        \n",
    "        \n",
    "    def call(self,X,training = None):\n",
    "        Z = self.in_layer(X)\n",
    "\n",
    "        for layer in self.hiddens:\n",
    "            Z = layer(Z)\n",
    "            \n",
    "        return self.out(Z)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 4096\n",
    "lr_1 = 1e-4\n",
    "lr_2 = 1e-4\n",
    "momentum = .90\n",
    "layers = 1\n",
    "n_neurons = 100\n",
    "activation = 'relu'\n",
    "\n",
    "model = my_model(n_layers = layers, n_neurons= n_neurons, activation= activation)\n",
    "loss_function = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "upper_layers_optimizer = keras.optimizers.Nadam(learning_rate = lr_1)\n",
    "bottom_layers_optimizer = keras.optimizers.RMSprop(learning_rate = lr_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 1.9636   Mean Training Accuracy: 0.3450 || Mean Validation Loss: 1.9632   Mean Validation Accuracy: 0.3396\n",
      "\n",
      "epoch: 2 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 1.7241   Mean Training Accuracy: 0.4962 || Mean Validation Loss: 1.7260   Mean Validation Accuracy: 0.4952\n",
      "\n",
      "epoch: 3 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 1.5316   Mean Training Accuracy: 0.6111 || Mean Validation Loss: 1.5364   Mean Validation Accuracy: 0.6041\n",
      "\n",
      "epoch: 4 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 1.3752   Mean Training Accuracy: 0.6426 || Mean Validation Loss: 1.3828   Mean Validation Accuracy: 0.6351\n",
      "\n",
      "epoch: 5 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 1.2486   Mean Training Accuracy: 0.6612 || Mean Validation Loss: 1.2582   Mean Validation Accuracy: 0.6544\n",
      "\n",
      "epoch: 6 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 1.1450   Mean Training Accuracy: 0.6728 || Mean Validation Loss: 1.1560   Mean Validation Accuracy: 0.6656\n",
      "\n",
      "epoch: 7 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 1.0594   Mean Training Accuracy: 0.6890 || Mean Validation Loss: 1.0720   Mean Validation Accuracy: 0.6834\n",
      "\n",
      "epoch: 8 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.9882   Mean Training Accuracy: 0.7011 || Mean Validation Loss: 1.0020   Mean Validation Accuracy: 0.6948\n",
      "\n",
      "epoch: 9 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.9315   Mean Training Accuracy: 0.7123 || Mean Validation Loss: 0.9454   Mean Validation Accuracy: 0.7053\n",
      "\n",
      "epoch: 10 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.8819   Mean Training Accuracy: 0.7234 || Mean Validation Loss: 0.8963   Mean Validation Accuracy: 0.7163\n",
      "\n",
      "epoch: 11 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.8418   Mean Training Accuracy: 0.7345 || Mean Validation Loss: 0.8567   Mean Validation Accuracy: 0.7285\n",
      "\n",
      "epoch: 12 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.8060   Mean Training Accuracy: 0.7444 || Mean Validation Loss: 0.8215   Mean Validation Accuracy: 0.7362\n",
      "\n",
      "epoch: 13 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.7769   Mean Training Accuracy: 0.7535 || Mean Validation Loss: 0.7926   Mean Validation Accuracy: 0.7442\n",
      "\n",
      "epoch: 14 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.7502   Mean Training Accuracy: 0.7605 || Mean Validation Loss: 0.7662   Mean Validation Accuracy: 0.7512\n",
      "\n",
      "epoch: 15 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.7276   Mean Training Accuracy: 0.7708 || Mean Validation Loss: 0.7437   Mean Validation Accuracy: 0.7615\n",
      "\n",
      "epoch: 16 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.7075   Mean Training Accuracy: 0.7761 || Mean Validation Loss: 0.7241   Mean Validation Accuracy: 0.7643\n",
      "\n",
      "epoch: 17 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6910   Mean Training Accuracy: 0.7799 || Mean Validation Loss: 0.7081   Mean Validation Accuracy: 0.7692\n",
      "\n",
      "epoch: 18 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6744   Mean Training Accuracy: 0.7858 || Mean Validation Loss: 0.6915   Mean Validation Accuracy: 0.7741\n",
      "\n",
      "epoch: 19 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6608   Mean Training Accuracy: 0.7886 || Mean Validation Loss: 0.6776   Mean Validation Accuracy: 0.7833\n",
      "\n",
      "epoch: 20 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6459   Mean Training Accuracy: 0.7944 || Mean Validation Loss: 0.6630   Mean Validation Accuracy: 0.7858\n",
      "\n",
      "epoch: 21 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6339   Mean Training Accuracy: 0.7973 || Mean Validation Loss: 0.6513   Mean Validation Accuracy: 0.7879\n",
      "\n",
      "epoch: 22 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6219   Mean Training Accuracy: 0.8007 || Mean Validation Loss: 0.6392   Mean Validation Accuracy: 0.7918\n",
      "\n",
      "epoch: 23 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6131   Mean Training Accuracy: 0.8026 || Mean Validation Loss: 0.6306   Mean Validation Accuracy: 0.7913\n",
      "\n",
      "epoch: 24 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.6033   Mean Training Accuracy: 0.8061 || Mean Validation Loss: 0.6206   Mean Validation Accuracy: 0.7957\n",
      "\n",
      "epoch: 25 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5934   Mean Training Accuracy: 0.8088 || Mean Validation Loss: 0.6108   Mean Validation Accuracy: 0.8000\n",
      "\n",
      "epoch: 26 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5865   Mean Training Accuracy: 0.8102 || Mean Validation Loss: 0.6035   Mean Validation Accuracy: 0.8017\n",
      "\n",
      "epoch: 27 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5777   Mean Training Accuracy: 0.8120 || Mean Validation Loss: 0.5952   Mean Validation Accuracy: 0.8031\n",
      "\n",
      "epoch: 28 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5718   Mean Training Accuracy: 0.8146 || Mean Validation Loss: 0.5890   Mean Validation Accuracy: 0.8051\n",
      "\n",
      "epoch: 29 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5640   Mean Training Accuracy: 0.8170 || Mean Validation Loss: 0.5812   Mean Validation Accuracy: 0.8063\n",
      "\n",
      "epoch: 30 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5578   Mean Training Accuracy: 0.8171 || Mean Validation Loss: 0.5752   Mean Validation Accuracy: 0.8073\n",
      "\n",
      "epoch: 31 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5522   Mean Training Accuracy: 0.8192 || Mean Validation Loss: 0.5697   Mean Validation Accuracy: 0.8099\n",
      "\n",
      "epoch: 32 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5480   Mean Training Accuracy: 0.8196 || Mean Validation Loss: 0.5656   Mean Validation Accuracy: 0.8094\n",
      "\n",
      "epoch: 33 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5451   Mean Training Accuracy: 0.8178 || Mean Validation Loss: 0.5632   Mean Validation Accuracy: 0.8096\n",
      "\n",
      "epoch: 34 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5394   Mean Training Accuracy: 0.8219 || Mean Validation Loss: 0.5560   Mean Validation Accuracy: 0.8143\n",
      "\n",
      "epoch: 35 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5329   Mean Training Accuracy: 0.8248 || Mean Validation Loss: 0.5504   Mean Validation Accuracy: 0.8171\n",
      "\n",
      "epoch: 36 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5282   Mean Training Accuracy: 0.8250 || Mean Validation Loss: 0.5462   Mean Validation Accuracy: 0.8165\n",
      "\n",
      "epoch: 37 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5237   Mean Training Accuracy: 0.8277 || Mean Validation Loss: 0.5413   Mean Validation Accuracy: 0.8175\n",
      "\n",
      "epoch: 38 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5191   Mean Training Accuracy: 0.8289 || Mean Validation Loss: 0.5364   Mean Validation Accuracy: 0.8202\n",
      "\n",
      "epoch: 39 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5167   Mean Training Accuracy: 0.8284 || Mean Validation Loss: 0.5349   Mean Validation Accuracy: 0.8199\n",
      "\n",
      "epoch: 40 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5118   Mean Training Accuracy: 0.8305 || Mean Validation Loss: 0.5293   Mean Validation Accuracy: 0.8223\n",
      "\n",
      "epoch: 41 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5083   Mean Training Accuracy: 0.8316 || Mean Validation Loss: 0.5257   Mean Validation Accuracy: 0.8227\n",
      "\n",
      "epoch: 42 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5050   Mean Training Accuracy: 0.8342 || Mean Validation Loss: 0.5214   Mean Validation Accuracy: 0.8246\n",
      "\n",
      "epoch: 43 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.5017   Mean Training Accuracy: 0.8340 || Mean Validation Loss: 0.5185   Mean Validation Accuracy: 0.8263\n",
      "\n",
      "epoch: 44 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4983   Mean Training Accuracy: 0.8349 || Mean Validation Loss: 0.5154   Mean Validation Accuracy: 0.8262\n",
      "\n",
      "epoch: 45 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4943   Mean Training Accuracy: 0.8367 || Mean Validation Loss: 0.5114   Mean Validation Accuracy: 0.8279\n",
      "\n",
      "epoch: 46 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4914   Mean Training Accuracy: 0.8370 || Mean Validation Loss: 0.5089   Mean Validation Accuracy: 0.8281\n",
      "\n",
      "epoch: 47 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4886   Mean Training Accuracy: 0.8383 || Mean Validation Loss: 0.5060   Mean Validation Accuracy: 0.8298\n",
      "\n",
      "epoch: 48 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4864   Mean Training Accuracy: 0.8392 || Mean Validation Loss: 0.5034   Mean Validation Accuracy: 0.8290\n",
      "\n",
      "epoch: 49 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4847   Mean Training Accuracy: 0.8385 || Mean Validation Loss: 0.5025   Mean Validation Accuracy: 0.8302\n",
      "\n",
      "epoch: 50 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4813   Mean Training Accuracy: 0.8410 || Mean Validation Loss: 0.4985   Mean Validation Accuracy: 0.8322\n",
      "\n",
      "epoch: 51 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4786   Mean Training Accuracy: 0.8415 || Mean Validation Loss: 0.4956   Mean Validation Accuracy: 0.8327\n",
      "\n",
      "epoch: 52 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4765   Mean Training Accuracy: 0.8416 || Mean Validation Loss: 0.4937   Mean Validation Accuracy: 0.8306\n",
      "\n",
      "epoch: 53 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4742   Mean Training Accuracy: 0.8426 || Mean Validation Loss: 0.4917   Mean Validation Accuracy: 0.8328\n",
      "\n",
      "epoch: 54 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4711   Mean Training Accuracy: 0.8437 || Mean Validation Loss: 0.4882   Mean Validation Accuracy: 0.8329\n",
      "\n",
      "epoch: 55 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4692   Mean Training Accuracy: 0.8444 || Mean Validation Loss: 0.4867   Mean Validation Accuracy: 0.8329\n",
      "\n",
      "epoch: 56 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4668   Mean Training Accuracy: 0.8452 || Mean Validation Loss: 0.4845   Mean Validation Accuracy: 0.8347\n",
      "\n",
      "epoch: 57 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4648   Mean Training Accuracy: 0.8457 || Mean Validation Loss: 0.4823   Mean Validation Accuracy: 0.8358\n",
      "\n",
      "epoch: 58 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4638   Mean Training Accuracy: 0.8452 || Mean Validation Loss: 0.4820   Mean Validation Accuracy: 0.8346\n",
      "\n",
      "epoch: 59 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4613   Mean Training Accuracy: 0.8470 || Mean Validation Loss: 0.4789   Mean Validation Accuracy: 0.8370\n",
      "\n",
      "epoch: 60 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4590   Mean Training Accuracy: 0.8475 || Mean Validation Loss: 0.4764   Mean Validation Accuracy: 0.8374\n",
      "\n",
      "epoch: 61 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4575   Mean Training Accuracy: 0.8476 || Mean Validation Loss: 0.4748   Mean Validation Accuracy: 0.8373\n",
      "\n",
      "epoch: 62 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4565   Mean Training Accuracy: 0.8470 || Mean Validation Loss: 0.4747   Mean Validation Accuracy: 0.8381\n",
      "\n",
      "epoch: 63 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4537   Mean Training Accuracy: 0.8488 || Mean Validation Loss: 0.4711   Mean Validation Accuracy: 0.8387\n",
      "\n",
      "epoch: 64 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4541   Mean Training Accuracy: 0.8487 || Mean Validation Loss: 0.4719   Mean Validation Accuracy: 0.8387\n",
      "\n",
      "epoch: 65 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4508   Mean Training Accuracy: 0.8495 || Mean Validation Loss: 0.4689   Mean Validation Accuracy: 0.8397\n",
      "\n",
      "epoch: 66 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4495   Mean Training Accuracy: 0.8500 || Mean Validation Loss: 0.4675   Mean Validation Accuracy: 0.8393\n",
      "\n",
      "epoch: 67 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4471   Mean Training Accuracy: 0.8505 || Mean Validation Loss: 0.4650   Mean Validation Accuracy: 0.8409\n",
      "\n",
      "epoch: 68 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4453   Mean Training Accuracy: 0.8514 || Mean Validation Loss: 0.4636   Mean Validation Accuracy: 0.8411\n",
      "\n",
      "epoch: 69 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4439   Mean Training Accuracy: 0.8518 || Mean Validation Loss: 0.4615   Mean Validation Accuracy: 0.8427\n",
      "\n",
      "epoch: 70 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4436   Mean Training Accuracy: 0.8515 || Mean Validation Loss: 0.4624   Mean Validation Accuracy: 0.8425\n",
      "\n",
      "epoch: 71 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4413   Mean Training Accuracy: 0.8524 || Mean Validation Loss: 0.4590   Mean Validation Accuracy: 0.8425\n",
      "\n",
      "epoch: 72 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4416   Mean Training Accuracy: 0.8524 || Mean Validation Loss: 0.4597   Mean Validation Accuracy: 0.8440\n",
      "\n",
      "epoch: 73 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4389   Mean Training Accuracy: 0.8530 || Mean Validation Loss: 0.4573   Mean Validation Accuracy: 0.8429\n",
      "\n",
      "epoch: 74 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4368   Mean Training Accuracy: 0.8529 || Mean Validation Loss: 0.4550   Mean Validation Accuracy: 0.8436\n",
      "\n",
      "epoch: 75 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4371   Mean Training Accuracy: 0.8522 || Mean Validation Loss: 0.4561   Mean Validation Accuracy: 0.8438\n",
      "\n",
      "epoch: 76 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4340   Mean Training Accuracy: 0.8535 || Mean Validation Loss: 0.4523   Mean Validation Accuracy: 0.8447\n",
      "\n",
      "epoch: 77 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4328   Mean Training Accuracy: 0.8548 || Mean Validation Loss: 0.4512   Mean Validation Accuracy: 0.8452\n",
      "\n",
      "epoch: 78 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4330   Mean Training Accuracy: 0.8534 || Mean Validation Loss: 0.4520   Mean Validation Accuracy: 0.8446\n",
      "\n",
      "epoch: 79 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4341   Mean Training Accuracy: 0.8531 || Mean Validation Loss: 0.4538   Mean Validation Accuracy: 0.8441\n",
      "\n",
      "epoch: 80 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4292   Mean Training Accuracy: 0.8560 || Mean Validation Loss: 0.4480   Mean Validation Accuracy: 0.8450\n",
      "\n",
      "epoch: 81 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4280   Mean Training Accuracy: 0.8558 || Mean Validation Loss: 0.4465   Mean Validation Accuracy: 0.8470\n",
      "\n",
      "epoch: 82 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4268   Mean Training Accuracy: 0.8566 || Mean Validation Loss: 0.4455   Mean Validation Accuracy: 0.8466\n",
      "\n",
      "epoch: 83 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4260   Mean Training Accuracy: 0.8571 || Mean Validation Loss: 0.4449   Mean Validation Accuracy: 0.8469\n",
      "\n",
      "epoch: 84 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4259   Mean Training Accuracy: 0.8563 || Mean Validation Loss: 0.4434   Mean Validation Accuracy: 0.8485\n",
      "\n",
      "epoch: 85 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4240   Mean Training Accuracy: 0.8573 || Mean Validation Loss: 0.4426   Mean Validation Accuracy: 0.8482\n",
      "\n",
      "epoch: 86 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4226   Mean Training Accuracy: 0.8573 || Mean Validation Loss: 0.4418   Mean Validation Accuracy: 0.8484\n",
      "\n",
      "epoch: 87 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4213   Mean Training Accuracy: 0.8581 || Mean Validation Loss: 0.4402   Mean Validation Accuracy: 0.8479\n",
      "\n",
      "epoch: 88 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4203   Mean Training Accuracy: 0.8592 || Mean Validation Loss: 0.4390   Mean Validation Accuracy: 0.8490\n",
      "\n",
      "epoch: 89 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4194   Mean Training Accuracy: 0.8596 || Mean Validation Loss: 0.4388   Mean Validation Accuracy: 0.8479\n",
      "\n",
      "epoch: 90 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4182   Mean Training Accuracy: 0.8597 || Mean Validation Loss: 0.4375   Mean Validation Accuracy: 0.8496\n",
      "\n",
      "epoch: 91 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4169   Mean Training Accuracy: 0.8596 || Mean Validation Loss: 0.4360   Mean Validation Accuracy: 0.8503\n",
      "\n",
      "epoch: 92 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4157   Mean Training Accuracy: 0.8597 || Mean Validation Loss: 0.4350   Mean Validation Accuracy: 0.8491\n",
      "\n",
      "epoch: 93 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4152   Mean Training Accuracy: 0.8594 || Mean Validation Loss: 0.4342   Mean Validation Accuracy: 0.8503\n",
      "\n",
      "epoch: 94 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4139   Mean Training Accuracy: 0.8602 || Mean Validation Loss: 0.4333   Mean Validation Accuracy: 0.8494\n",
      "\n",
      "epoch: 95 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4139   Mean Training Accuracy: 0.8599 || Mean Validation Loss: 0.4325   Mean Validation Accuracy: 0.8516\n",
      "\n",
      "epoch: 96 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4122   Mean Training Accuracy: 0.8605 || Mean Validation Loss: 0.4320   Mean Validation Accuracy: 0.8499\n",
      "\n",
      "epoch: 97 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4140   Mean Training Accuracy: 0.8592 || Mean Validation Loss: 0.4341   Mean Validation Accuracy: 0.8520\n",
      "\n",
      "epoch: 98 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4110   Mean Training Accuracy: 0.8611 || Mean Validation Loss: 0.4300   Mean Validation Accuracy: 0.8521\n",
      "\n",
      "epoch: 99 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4092   Mean Training Accuracy: 0.8617 || Mean Validation Loss: 0.4289   Mean Validation Accuracy: 0.8516\n",
      "\n",
      "epoch: 100 - Current iteration: 11       [------------------------------------------------------------------------------------------          ]\n",
      "Mean Training Loss: 0.4083   Mean Training Accuracy: 0.8617 || Mean Validation Loss: 0.4281   Mean Validation Accuracy: 0.8517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = len(X_train) //batch_size\n",
    "\n",
    "all_losses_training, all_losses_validation = [],[]\n",
    "all_acc_training, all_acc_validation = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(iterations):\n",
    "        X_batch,y_batch = batch_extraction(X_train,y_train,batch_size = batch_size)\n",
    "        \n",
    "        with tf.GradientTape(persistent = True) as tape: #persistent since we will be reading the gradients per layer\n",
    "            y_pred = model(X_batch,training = True)\n",
    "            loss = loss_function(y_batch,y_pred)\n",
    "        \n",
    "        for this_layer in model.layers:\n",
    "            this_grad = tape.gradient(loss,model.get_layer(this_layer.name).trainable_variables) #get the grad\n",
    "            if not this_grad: #if layer has no trainable parameters\n",
    "                continue\n",
    "            \n",
    "            if this_layer.name.find('inner') >= 0: #this is an inner layer\n",
    "                bottom_layers_optimizer.apply_gradients(zip(this_grad,model.get_layer(this_layer.name).trainable_variables))\n",
    "            else: #this is an outer layer\n",
    "                upper_layers_optimizer.apply_gradients(zip(this_grad,model.get_layer(this_layer.name).trainable_variables))\n",
    "        \n",
    "        print_info(epoch,iter,iterations)\n",
    "        \n",
    "    ## Validation Metrics\n",
    "    y_pred_train  = model(X_train,training = False)\n",
    "    train_loss = loss_function(y_train,y_pred_train)\n",
    "    train_accuracy = accuracy_score(y_train,np.argmax(y_pred_train,axis=1))\n",
    "        \n",
    "    ## Prediction Metrics\n",
    "    y_pred_val  = model(X_val,training = False)\n",
    "    val_loss = loss_function(y_val,y_pred_val)\n",
    "    val_accuracy = accuracy_score(y_val,np.argmax(y_pred_val,axis=1))\n",
    "    \n",
    "    all_losses_training.append(train_loss)\n",
    "    all_losses_validation.append(val_loss)\n",
    "    all_acc_training.append(train_accuracy)\n",
    "    all_acc_validation.append(val_accuracy)\n",
    "    \n",
    "    print_info(epoch,iter,iterations,train_loss,train_accuracy,val_loss,val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x284343ab070>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,3))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(range(epochs),all_losses_training,'--b',label = 'Training Loss')\n",
    "plt.plot(range(epochs),all_losses_validation,'--r',label = 'Validation loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(range(epochs),all_acc_training,'--b',label = 'Training accuracy')\n",
    "plt.plot(range(epochs),all_acc_validation,'--r',label = 'Validation accuracy')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5effdde1fd048803b3704d23bd87152bc8d30461613bdeefdecf9d4ac1d2da28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
