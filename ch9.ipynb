{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Saved Without Images to Prevent Overloading GitHub***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samps_cluster = 1000\n",
    "x_mns =[-2.7,-2.7,-2.7,-1.5,0]\n",
    "y_mns =[1.2 ,1.8 ,2.8 ,2.3 ,2.5]\n",
    "var = [.1,.1,.1,.3,.25]\n",
    "\n",
    "X = [[],[]]\n",
    "[X[0].extend(np.random.normal(loc = x_mns[k],scale = var[k],size = n_samps_cluster)) for k in range(5)];\n",
    "[X[1].extend(np.random.normal(loc = y_mns[k],scale = var[k],size = n_samps_cluster)) for k in range(5)];\n",
    "X = np.array(X).T\n",
    "\n",
    "\n",
    "def plot_raw_data(X):\n",
    "    plt.scatter(X[:,0],X[:,1],color='red')\n",
    "    plt.ylim([.8,3.5])\n",
    "    plt.xlim([-3,1.2])\n",
    "    \n",
    "plot_raw_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centroids of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundaries(x_range,y_range,model):\n",
    "    xgrid,ygrid = np.meshgrid(x_range,y_range)\n",
    "    mesh_grid_cols = model.predict(np.c_[xgrid.flatten(),ygrid.flatten()])\n",
    "    plt.contourf(x_range,y_range,mesh_grid_cols.reshape(xgrid.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(np.arange(-3,1.2,1/100),np.arange(.8,3.5,1/100),kmeans)\n",
    "plot_raw_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = np.array([[-2,-1.5,-.5,.5],[1.0,1.5,3.2,1.0]]).T\n",
    "ynew = kmeans.predict(xnew)\n",
    "print(ynew)\n",
    "print(kmeans.transform(xnew))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.inertia_)\n",
    "print(kmeans.score(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini Batch K Means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import time\n",
    "\n",
    "inertia_km, inertia_mb, time_km, time_mb = [],[],[],[]\n",
    "\n",
    "all_k = np.arange(2,40,2)\n",
    "for k in all_k:\n",
    "    start_mb = time.time()\n",
    "    mb = MiniBatchKMeans(n_clusters=k,random_state=42).fit(X)\n",
    "    time_mb.append(time.time() - start_mb)\n",
    "    \n",
    "    inertia_mb.append(mb.inertia_)\n",
    "    \n",
    "    start_km = time.time()\n",
    "    km = KMeans(n_clusters=k,random_state = 42).fit(X)\n",
    "    time_km.append(time.time() - start_km)\n",
    "    \n",
    "    inertia_km.append(km.inertia_)\n",
    "    \n",
    "    \n",
    "plt.subplot(121);\n",
    "plt.plot(all_k,inertia_mb,color='blue',label='Mini-batch K-Means')\n",
    "plt.plot(all_k,inertia_km,color='red',label='K-Means')\n",
    "plt.title('Inertia')\n",
    "plt.xlabel('K')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122);\n",
    "plt.plot(all_k,time_mb,'-ob')\n",
    "plt.plot(all_k,time_km,'--r')\n",
    "plt.title('Training time (seconds)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouttes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "inertia_km = []\n",
    "silhoutte  = []\n",
    "sub_x, sub_y = [],[]\n",
    "\n",
    "n_samps = X.shape[0]\n",
    "all_k = np.arange(2,9)\n",
    "for k in all_k:\n",
    "    km = KMeans(n_clusters=k,random_state = 42).fit(X)\n",
    "    \n",
    "    inertia_km.append(km.inertia_)\n",
    "    silhoutte.append(silhouette_score(X,km.labels_))\n",
    "    \n",
    "    if k in [3,4,5,6]:\n",
    "        this_x,this_y = [],[]\n",
    "        \n",
    "        sil_samps = silhouette_samples(X,km.labels_)\n",
    "        for c in range(k):\n",
    "            ind_this_k = np.argwhere(km.labels_ == c)\n",
    "\n",
    "            this_x.append(np.sort(sil_samps[ind_this_k.flatten()]))\n",
    "            this_y.append(np.linspace(c - len(ind_this_k) / n_samps,c + len(ind_this_k) / n_samps,len(ind_this_k)))\n",
    "                        \n",
    "        sub_x.append(this_x)\n",
    "        sub_y.append(this_y)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(all_k,inertia_km,'-ob')\n",
    "plt.xticks(range(1,8),labels=range(1,8));\n",
    "plt.ylabel('Inertia')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(all_k,silhoutte,'-ob')\n",
    "plt.xticks(range(1,8),labels=range(1,8));\n",
    "plt.ylabel('Silhoutte score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figgy = plt.figure(figsize=(10,10))\n",
    "my_colors = get_cmap('tab10').colors\n",
    "for i,k in enumerate([3,4,5,6]):\n",
    "    for c in range(len(sub_x[i])):\n",
    "        plt.subplot(2,2,i+1)\n",
    "        \n",
    "        plt.plot(sub_x[i][c],sub_y[i][c],color=my_colors[c])\n",
    "        plt.fill_betweenx(sub_y[i][c],sub_x[i][c],np.min(sub_x[i][c]),color=my_colors[c])\n",
    "        \n",
    "        plt.title(f'k = {k}')\n",
    "        plt.ylabel('Cluster')\n",
    "        plt.xlabel('Silhouette Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering for PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dig,y_dig = load_digits(return_X_y=True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_dig,y_dig,test_size=.2)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter = 5000).fit(X_train,y_train)\n",
    "log_reg.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('k_means',KMeans(n_clusters = 50)),\n",
    "    ('log_reg',LogisticRegression(max_iter = 10000))\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train,y_train)\n",
    "full_pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'k_means__n_clusters': np.arange(96,101)}\n",
    "\n",
    "grid_cv = GridSearchCV(full_pipeline,params,cv = 3,verbose=2).fit(X_train,y_train)\n",
    "print(grid_cv.best_params_)\n",
    "grid_cv.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labeled = 50\n",
    "log_reg = LogisticRegression(max_iter = 5000).fit(X_train[:n_labeled],y_train[:n_labeled])\n",
    "log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[rep_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "kmeans = KMeans(n_clusters = k,random_state=42)\n",
    "X_digits = kmeans.fit_transform(X_train)\n",
    "rep_indx = np.argmin(X_digits,axis=0)\n",
    "rep_digits = X_train[rep_indx]\n",
    "\n",
    "figgy = plt.figure(figsize=(8,8))\n",
    "for i in range(len(rep_digits)):\n",
    "    plt.subplot(5,10,i+1)\n",
    "    plt.imshow(rep_digits[i].reshape(8,8))\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "rep_labels = [5,8,1,0,1,7,9,2,6,3,\n",
    "              4,5,3,7,4,4,5,2,8,2,\n",
    "              2,6,0,1,1,3,8,6,6,9,\n",
    "              4,0,7,9,7,3,5,8,9,2,\n",
    "              9,1,7,5,8,7,4,3,1,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually label selected samples close to cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter = 5000).fit(rep_digits,rep_labels)\n",
    "log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propagate label to all labels in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_propagated = np.empty(len(X_train),dtype = np.int32)\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_==i] = rep_labels[i]\n",
    "    \n",
    "    \n",
    "log_reg = LogisticRegression(max_iter =5000).fit(X_train,y_train_propagated)\n",
    "log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propagate label to only a small percentage of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = 20\n",
    "\n",
    "ind_to_train = []\n",
    "for i in range(k):\n",
    "    cluster_dist = X_digits[kmeans.labels_ == i , i] #find the digits for this cluster\n",
    "    cut_off = np.percentile(cluster_dist,perc)  \n",
    "     \n",
    "    ind_to_train.extend(np.argwhere(X_digits[:, i ] < cut_off).flatten()) #identify the indices for the samples closest to the centroids\n",
    "    \n",
    "X_partial = X_train[ind_to_train]   \n",
    "y_partial = y_train_propagated[ind_to_train]\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=5000).fit(X_partial,y_partial)\n",
    "log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X,y = make_moons(n_samples = 1000,noise = 0.05)\n",
    "dbscan = DBSCAN(eps = 0.2,min_samples=5).fit(X)\n",
    "\n",
    "dbscan.labels_[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dbscan.core_sample_indices_[0:10])\n",
    "print(dbscan.components_[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use KNN to classify new samples to existing clusters via core samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=50).fit(dbscan.components_,dbscan.labels_[dbscan.core_sample_indices_])\n",
    "\n",
    "Xnew = np.array([[-0.5,0],[0,0.5],[1,-0.1],[2,1]])\n",
    "print(knn.predict(Xnew))\n",
    "print(knn.predict_proba(Xnew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detector. If distance to nearest neighbor is greater than a threshold, set to -1 as an anomally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dist , y_pred_idx = knn.kneighbors(Xnew,n_neighbors=1)\n",
    "y_preds = dbscan.labels_[y_pred_idx]\n",
    "\n",
    "y_preds[y_dist > 0.2] = -1 \n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[],[]]\n",
    "[X[0].extend(np.random.normal(loc = x_mns[k],scale = var[k],size = n_samps_cluster)) for k in range(5)];\n",
    "[X[1].extend(np.random.normal(loc = y_mns[k],scale = var[k],size = n_samps_cluster)) for k in range(5)];\n",
    "X = np.array(X).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components = 3, n_init = 10).fit(X)\n",
    "print(gm.weights_)\n",
    "print(gm.means_)\n",
    "print(gm.covariances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gm.converged_)\n",
    "print(gm.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gm.predict(X))\n",
    "print(gm.predict_proba(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative models allow for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew,ynew = gm.sample(5)\n",
    "print(Xnew)\n",
    "print(ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gm.score_samples(Xnew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.radians(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = [-3,0,6]\n",
    "ym = [2,0,2]\n",
    "xv = [.5,.5,1]\n",
    "yv = [2, 2,3]\n",
    "\n",
    "rot_mat = lambda x,y : [x*np.cos(np.radians(-30)) - y*np.sin(np.radians(-30)) , x*np.sin(np.radians(-30)) + y*np.cos(np.radians(-30))]\n",
    "xdat,ydat = [],[]\n",
    "\n",
    "xdat.extend(np.random.normal(xm[k],xv[k],100) for k in range(3))\n",
    "ydat.extend(np.random.normal(ym[k],yv[k],100) for k in range(3))\n",
    "\n",
    "xdat[0],ydat[0] = rot_mat(xdat[0],ydat[0])\n",
    "xdat[1],ydat[1] = rot_mat(xdat[1],ydat[1])\n",
    "\n",
    "X = np.c_[np.r_[xdat[0], xdat[1],xdat[2]] , np.r_[ydat[0],ydat[1],ydat[2]]]\n",
    "\n",
    "\n",
    "plt.scatter(xdat,ydat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components = 3,n_init = 10).fit(X)\n",
    "\n",
    "plot_boundaries(np.arange(-5,10,1/100),np.arange(-10,13,1/100),gm)\n",
    "plot_raw_data(X)\n",
    "\n",
    "plt.ylim([-10,12])\n",
    "plt.xlim([-5,10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = gm.score_samples(X)\n",
    "density_threshold = np.percentile(densities,4)\n",
    "anomalies = X[densities < density_threshold]\n",
    "\n",
    "plot_boundaries(np.arange(-5,10,1/100),np.arange(-10,13,1/100),gm)\n",
    "plot_raw_data(X)\n",
    "plt.scatter(anomalies[:,0],anomalies[:,1],marker= 'x',color='blue')\n",
    "\n",
    "plt.ylim([-10,12])\n",
    "plt.xlim([-5,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "bgm = BayesianGaussianMixture(n_components=10,n_init=10)\n",
    "bgm.fit(X)\n",
    "np.round(bgm.weights_,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, y = fetch_olivetti_faces(random_state = 42, return_X_y= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffler = StratifiedShuffleSplit(n_splits = 1,test_size = .2)\n",
    "\n",
    "train_indx, test_indx = next(shuffler.split(X,y))\n",
    "X_train,y_train = X[train_indx],y[train_indx]\n",
    "X_tmp,y_tmp = X[test_indx],y[test_indx]\n",
    "\n",
    "val_shuffler = StratifiedShuffleSplit(n_splits = 1, test_size =.5)\n",
    "\n",
    "test_indx, val_indx = next(val_shuffler.split(X_tmp,y_tmp))\n",
    "X_val,y_val = X_tmp[val_indx],y_tmp[val_indx]\n",
    "X_test,y_test = X_tmp[test_indx],y_tmp[test_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = np.arange(2,200,5)\n",
    "sil_vals,inertia_vals = [],[]\n",
    "k_models = []\n",
    "\n",
    "    \n",
    "for k in k_vals:\n",
    "    kmeans = KMeans(n_clusters = k).fit(X_train)\n",
    "    \n",
    "    inertia_vals.append(kmeans.inertia_)\n",
    "    sil_vals.append(silhouette_score(X_train,kmeans.labels_))\n",
    "    k_models.append(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sil = np.argmax(sil_vals)\n",
    "best_model = k_models[max_sil]\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "\n",
    "plt.subplot(121); plt.plot(k_vals,sil_vals,'-ob'); plt.plot(k_vals[np.argmax(sil_vals)],np.max(sil_vals),color = 'r',marker='o')\n",
    "plt.xlabel('K'); plt.ylabel('Silhouette value'); plt.title(f'Optimum clusters: {k_vals[np.argmax(sil_vals)]}')\n",
    "plt.xticks(range(0,200,10),range(0,200,10));\n",
    "\n",
    "plt.subplot(122); plt.plot(k_vals,inertia_vals,'-ob'); plt.plot(k_vals[np.argmax(sil_vals)],inertia_vals[np.argmax(sil_vals)],color = 'r',marker='o')\n",
    "plt.xlabel('K'); plt.ylabel('Inertia value'); plt.title(f'Index: {np.argmax(sil_vals)}')\n",
    "plt.xticks(range(0,200,10),range(0,200,10));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = best_model.transform(X_train)\n",
    "best_transforms = np.argmin(X_transform,axis=0) #find the best transforms (closest to cluster centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = plt.hist(best_model.labels_,bins=50);\n",
    "plt.title('Distribution of faces per cluster');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = best_model.n_clusters\n",
    "ncols = int(counts[0].max())\n",
    "fig = plt.figure(figsize = (ncols,nrows))\n",
    "\n",
    "for c in range(best_model.n_clusters):\n",
    "    plt.subplot(nrows,ncols,c*ncols+1)\n",
    "    \n",
    "    plt.imshow(X_train[best_transforms[c],:].reshape(64,64),cmap= 'gray'); plt.xticks([]); plt.yticks([])\n",
    "    plt.ylabel(f'Cluster {c}'); plt.title(y_train[best_transforms[c]][0])\n",
    "    \n",
    "    other_in_cluster = np.argwhere(best_model.labels_ == c)\n",
    "    for i,others in enumerate(other_in_cluster,start = 1):\n",
    "        plt.subplot(nrows,ncols,c*ncols + i + 1)\n",
    "        plt.imshow(X_train[others,:].reshape(64,64),cmap='gray'); plt.xticks([]); plt.yticks([]); plt.title(y_train[others[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rfg = RandomForestClassifier(n_estimators = 120,random_state=42).fit(X_train,y_train)\n",
    "ypred = rfg.predict(X_val)\n",
    "r2_score(y_val,ypred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = best_model.transform(X_train)\n",
    "X_val_reduced = best_model.transform(X_val)\n",
    "\n",
    "rfg = RandomForestClassifier(n_estimators = 120, random_state = 42).fit(X_train_reduced,y_train)\n",
    "ypred = rfg.predict(X_val_reduced)\n",
    "r2_score(y_val,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "my_pipe = Pipeline([\n",
    "    ('kmean',KMeans()),\n",
    "    ('rfg',RandomForestClassifier(n_estimators = 120,random_state=42))\n",
    "])\n",
    "\n",
    "params = {'kmean__n_clusters':np.arange(50,200,10)}\n",
    "\n",
    "gs_cv = GridSearchCV(my_pipe,params,cv=3,verbose = 4, error_score = 'raise').fit(np.r_[X_train, X_val],np.r_[y_train, y_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_cv.best_params_)\n",
    "print(gs_cv.best_score_)\n",
    "gs_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_X_train = np.c_[X_train, X_train_reduced]\n",
    "appended_X_val = np.c_[X_val, X_val_reduced]\n",
    "\n",
    "rnf = RandomForestClassifier(n_estimators = 120 , random_state=42)\n",
    "\n",
    "rnf.fit(appended_X_train,y_train)\n",
    "rnf.score(appended_X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_cv.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "my_pca = PCA(.99)\n",
    "\n",
    "\n",
    "X_train_pca = my_pca.fit_transform(X_train)\n",
    "X_val_pca = my_pca.transform(X_val)\n",
    "X_test_pca = my_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components = 40, n_init = 5,random_state = 42).fit(X_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate sampled faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen_faces = 20\n",
    "gen_faces_reduced , y_gen_faces = gmm.sample(n_samples = n_gen_faces)\n",
    "gen_faces  = my_pca.inverse_transform(gen_faces_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gen_faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,3))\n",
    "for s in range(n_gen_faces):\n",
    "    plt.subplot(2,20,s+1)\n",
    "    plt.imshow(X_train[np.argwhere(y_train == y_gen_faces[s])[0]].reshape(64,64),cmap = 'gray'); plt.yticks([]); plt.xticks([]); plt.title(y_gen_faces[s])\n",
    "    plt.subplot(2,20,20+s+1)\n",
    "    plt.imshow(gen_faces[s].reshape(64,64),cmap='gray'); plt.yticks([]); plt.xticks([]); plt.title(y_gen_faces[s])\n",
    "    \n",
    "plt.subplot(2,20,1); plt.ylabel('First of this Category')\n",
    "plt.subplot(2,20,20); plt.ylabel('Generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_samps = np.random.choice(range(len(X_train)),3)\n",
    "rot_good_X = X_train[rot_samps,:].reshape(-1,64,64)\n",
    "rot_bad_X = np.transpose(rot_good_X,axes = (0,2,1))\n",
    "\n",
    "flip_samps = np.random.choice(range(len(X_train)),3)\n",
    "flip_good_X = X_train[flip_samps,:].reshape(-1,64,64)\n",
    "flip_bad_X = flip_good_X[:,::-1]\n",
    "\n",
    "dark_samps = np.random.choice(range(len(X_train)),3)\n",
    "dark_good_X = X_train[dark_samps,:].reshape(-1,64,64)\n",
    "dark_bad_X = dark_good_X * .3\n",
    "\n",
    "all_bad = np.r_[rot_bad_X,flip_bad_X,dark_bad_X]\n",
    "all_good = np.r_[rot_good_X,flip_good_X,dark_good_X]\n",
    "\n",
    "labels = y_train[np.r_[rot_samps,flip_samps,dark_samps]]\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "for s in range(9):\n",
    "    plt.subplot(2,9,s+1)\n",
    "    plt.imshow(all_good[s],cmap = 'gray',vmin = 0, vmax = 1); plt.xticks([]); plt.yticks([]); plt.title(labels[s])\n",
    "    plt.subplot(2,9,9+s+1)\n",
    "    plt.imshow(all_bad[s],cmap = 'gray',vmin = 0, vmax = 1); plt.xticks([]); plt.yticks([]); plt.title(labels[s])\n",
    "    \n",
    "    \n",
    "good_pca = my_pca.transform(all_good.reshape(9,-1))\n",
    "bad_pca = my_pca.transform(all_bad.reshape(9,-1))\n",
    "\n",
    "print(f'Average sample score for the original images: {np.mean(gmm.score_samples(good_pca))}')\n",
    "print(f'Average sample score for the deformed images: {np.mean(gmm.score_samples(bad_pca))}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "my_pca = PCA(.99)\n",
    "X_train_pca = my_pca.fit_transform(X_train)\n",
    "X_train_reconstructed = my_pca.inverse_transform(X_train_pca)\n",
    "\n",
    "reconstruction_error_original = mean_squared_error(X_train,X_train_reconstructed)\n",
    "\n",
    "X_bad = all_bad.reshape(all_bad.shape[0],-1)\n",
    "X_bad_pca = my_pca.transform(X_bad)\n",
    "X_bad_reconstruct = my_pca.inverse_transform(X_bad_pca)\n",
    "reconstruction_error_bad = mean_squared_error(X_bad,X_bad_reconstruct)\n",
    "\n",
    "print(f'Training reconstruction: {reconstruction_error_original}')\n",
    "print(f'Morphed reconstruction: {reconstruction_error_bad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_good_reconstructed = my_pca.inverse_transform(my_pca.transform(all_good.reshape(9,-1)))\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "for s in range(9):\n",
    "    plt.subplot(4,9,s+1)\n",
    "    plt.imshow(all_good[s],cmap = 'gray',vmin = 0, vmax = 1); plt.xticks([]); plt.yticks([]); plt.title(labels[s]);\n",
    "    plt.subplot(4,9,9+s+1)\n",
    "    plt.imshow(X_good_reconstructed[s].reshape(64,64),cmap = 'gray',vmin = 0, vmax = 1); plt.xticks([]); plt.yticks([]); plt.title(labels[s])\n",
    "    \n",
    "    plt.subplot(4,9,18+s+1)\n",
    "    plt.imshow(all_bad[s],cmap = 'gray',vmin = 0, vmax = 1); plt.xticks([]); plt.yticks([]); plt.title(labels[s]);\n",
    "    plt.subplot(4,9,27+s+1)\n",
    "    plt.imshow(X_bad_reconstruct[s].reshape(64,64),cmap = 'gray',vmin = 0, vmax = 1); plt.xticks([]); plt.yticks([]); plt.title(labels[s])\n",
    "    \n",
    "    \n",
    "plt.subplot(4,9,1); plt.ylabel('Original');\n",
    "plt.subplot(4,9,10); plt.ylabel('Reconstructed Normal');\n",
    "plt.subplot(4,9,19); plt.ylabel('Morphed ');\n",
    "plt.subplot(4,9,28); plt.ylabel('Reconstructed Morphed');"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5effdde1fd048803b3704d23bd87152bc8d30461613bdeefdecf9d4ac1d2da28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
